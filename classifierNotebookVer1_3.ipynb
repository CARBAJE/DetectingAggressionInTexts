{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_md",
   "metadata": {},
   "source": [
    "# Modelo de Clasificación Jerárquica con Aumento de Datos v3.0\n",
    "\n",
    "Este notebook implementa un pipeline avanzado de clasificación jerárquica:\n",
    "\n",
    "1.  **Carga y Preprocesamiento**: Usa `hate_speech_twitter` y realiza limpieza de texto (tokenización, stemming, etc.).\n",
    "2.  **Generación de Características Dual**: Crea embeddings de BERT y vectores TF-IDF.\n",
    "3.  **Aumento de Datos Sintéticos**: Utiliza **CTGAN** de la librería `sdv` para generar datos sintéticos y **balancear las sub-categorías** de discurso de odio en el conjunto de entrenamiento, mejorando la robustez del modelo.\n",
    "4.  **Entrenamiento de Clasificador Principal (Nivel 1)**: Entrena y optimiza un ensemble de cuatro modelos para distinguir entre `odio` y `no-odio`.\n",
    "5.  **Entrenamiento de Clasificador de Sub-categorías (Nivel 2)**: Entrena un modelo XGBoost para clasificar el **tipo de odio** (ej. sexismo, racismo) en los textos ya identificados como odio.\n",
    "6.  **Evaluación Jerárquica**: Evalúa el rendimiento del pipeline completo en dos niveles, reportando la precisión tanto en la detección de odio como en la clasificación de su tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_md",
   "metadata": {},
   "source": [
    "## 1. Instalación y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers torch datasets scikit-learn xgboost pandas seaborn matplotlib tqdm optuna nltk scipy sdv nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "\n",
      "ID de trabajo: hierarchical-job-1750836320\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_SAMPLES = 10000 # Aumentar para un mejor entrenamiento de sub-categorías\n",
    "MAX_TOKEN_LENGTH = 128\n",
    "\n",
    "# --- Configuración de Dispositivo (GPU o CPU) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# --- Definición de Rutas Locales ---\n",
    "job_id = f\"hierarchical-job-{int(time.time())}\"\n",
    "BASE_DIR = \"datos_locales\"\n",
    "PROCESSED_DIR = os.path.join(BASE_DIR, \"processed\", job_id)\n",
    "MODEL_OUTPUT_DIR = os.path.join(BASE_DIR, \"model_output\", job_id)\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
    "PROCESSED_DATA_PATH = os.path.join(PROCESSED_DIR, \"processed_data_with_embeddings.csv\")\n",
    "print(f\"\\nID de trabajo: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_load_md",
   "metadata": {},
   "source": [
    "## 2. Carga, Análisis y Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_load_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando dataset 'thefrankhsu/hate_speech_twitter'...\n",
      "Tomando una muestra aleatoria de 5679 registros (de un total de 5679).\n",
      "Distribución de etiquetas principales:\n",
      "main_label\n",
      "0    4163\n",
      "1    1516\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de sub-etiquetas (solo para 'odio'):\n",
      "sub_label_str\n",
      "Race                   523\n",
      "Sexual Orientation     429\n",
      "Gender                 279\n",
      "Physical Appearance     73\n",
      "Religion                52\n",
      "Behavior                40\n",
      "Class                   40\n",
      "Ethnicity               40\n",
      "Disability              40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mapeo de Sub-etiquetas: {'Behavior': 0, 'Class': 1, 'Disability': 2, 'Ethnicity': 3, 'Gender': 4, 'Physical Appearance': 5, 'Race': 6, 'Religion': 7, 'Sexual Orientation': 8, 'not-hate': 9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Limpiando Texto para Embeddings: 100%|██████████| 5679/5679 [00:00<00:00, 18824.90it/s]\n",
      "Aplicando Stemming para TF-IDF: 100%|██████████| 5679/5679 [00:00<00:00, 10888.97it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando dataset 'thefrankhsu/hate_speech_twitter'...\")\n",
    "dataset = load_dataset(\"thefrankhsu/hate_speech_twitter\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Renombrar columnas y manejar nulos en 'categories'\n",
    "df = df.rename(columns={'tweet': 'text_raw', 'label': 'main_label', 'categories': 'sub_label_str'})\n",
    "df['sub_label_str'] = df['sub_label_str'].fillna('not-hate')\n",
    "\n",
    "if MAX_SAMPLES is not None:\n",
    "    # Asegurarse de que el tamaño de la muestra no sea mayor que la población\n",
    "    sample_size = min(MAX_SAMPLES, len(df))\n",
    "    print(f\"Tomando una muestra aleatoria de {sample_size} registros (de un total de {len(df)}).\")\n",
    "    df = df.sample(n=sample_size, random_state=42, replace=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Distribución de etiquetas principales:\")\n",
    "print(df['main_label'].value_counts())\n",
    "\n",
    "print(\"\\nDistribución de sub-etiquetas (solo para 'odio'):\")\n",
    "print(df[df['main_label'] == 1]['sub_label_str'].value_counts())\n",
    "\n",
    "# Codificar sub-etiquetas\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sub_label_encoder = LabelEncoder()\n",
    "df['sub_label_encoded'] = sub_label_encoder.fit_transform(df['sub_label_str'])\n",
    "sub_label_mapping = dict(zip(sub_label_encoder.classes_, sub_label_encoder.transform(sub_label_encoder.classes_)))\n",
    "print(\"\\nMapeo de Sub-etiquetas:\", sub_label_mapping)\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "def clean_text(text, apply_stemming=False):\n",
    "    if pd.isna(text): return \"\"\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|#','', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "    if apply_stemming: words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "tqdm.pandas(desc=\"Limpiando Texto para Embeddings\")\n",
    "df['text_cleaned'] = df['text_raw'].progress_apply(lambda x: clean_text(x, apply_stemming=False))\n",
    "tqdm.pandas(desc=\"Aplicando Stemming para TF-IDF\")\n",
    "df['text_stemmed'] = df['text_cleaned'].progress_apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding_md",
   "metadata": {},
   "source": [
    "## 3. Generación de Embeddings y División de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedding_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo y tokenizador BERT: bert-base-uncased\n",
      "Generando embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:05<00:00, 35.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dividiendo Datos ---\n",
      "Tamaño Train: 3407, Val: 1136, Test: 1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cargando modelo y tokenizador BERT: {BERT_MODEL_NAME}\")\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model_bert = AutoModel.from_pretrained(BERT_MODEL_NAME).to(device)\n",
    "model_bert.eval()\n",
    "\n",
    "def get_bert_embeddings(batch_text):\n",
    "    inputs = tokenizer_bert(batch_text, padding=True, truncation=True, max_length=MAX_TOKEN_LENGTH, return_tensors='pt')\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bert(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "print(\"Generando embeddings...\")\n",
    "batch_size = 32\n",
    "all_embeddings = np.vstack([get_bert_embeddings(df.iloc[i:i+batch_size]['text_cleaned'].tolist()) for i in tqdm(range(0, len(df), batch_size))])\n",
    "\n",
    "embedding_cols = [f'dim_{i}' for i in range(all_embeddings.shape[1])]\n",
    "df_embeddings = pd.DataFrame(all_embeddings, columns=embedding_cols, index=df.index)\n",
    "df_processed = pd.concat([df, df_embeddings], axis=1)\n",
    "\n",
    "print(\"\\n--- Dividiendo Datos ---\")\n",
    "y_main = df_processed['main_label'].values\n",
    "df_trainval, df_test = train_test_split(df_processed, test_size=0.2, random_state=42, stratify=y_main)\n",
    "y_trainval_main = df_trainval['main_label'].values\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.25, random_state=42, stratify=y_trainval_main)\n",
    "\n",
    "print(f\"Tamaño Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "augmentation_md",
   "metadata": {},
   "source": [
    "## 4. Aumento de Datos Sintéticos para Sub-categorías (CTGAN)\n",
    "Nos enfocamos en el desbalance de las sub-categorías de 'odio'. Usaremos CTGAN para generar nuevos datos de entrenamiento para las clases minoritarias, basándonos en sus embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augmentation_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparando datos para aumento ---\n",
      "Distribución de sub-categorías ANTES del aumento:\n",
      "sub_label_str\n",
      "Race                   321\n",
      "Sexual Orientation     271\n",
      "Gender                 158\n",
      "Physical Appearance     43\n",
      "Religion                27\n",
      "Class                   25\n",
      "Ethnicity               23\n",
      "Disability              22\n",
      "Behavior                20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Nuevo encoder para Nivel 2 creado. Clases: ['Behavior' 'Class' 'Disability' 'Ethnicity' 'Gender'\n",
      " 'Physical Appearance' 'Race' 'Religion' 'Sexual Orientation']\n",
      "\n",
      "Actualizando metadatos para tratar embeddings como numéricos continuos...\n",
      "Usando GPU: True\n",
      "\n",
      "Entrenando CTGAN para generar datos sintéticos... (Usando GPU: True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sdv\\single_table\\base.py:162: FutureWarning: The 'SingleTableMetadata' is deprecated. Please use the new 'Metadata' class for synthesizers.\n",
      "  warnings.warn(DEPRECATION_MSG, FutureWarning)\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sdv\\single_table\\base.py:128: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PerformanceAlert: Using the CTGANSynthesizer on this data is not recommended. To model this data, CTGAN will generate a large number of columns.\n",
      "\n",
      "Original Column Name   Est # of Columns (CTGAN)\n",
      "sub_label_str          9\n",
      "dim_0                  11\n",
      "dim_1                  11\n",
      "dim_2                  11\n",
      "dim_3                  11\n",
      "dim_4                  11\n",
      "dim_5                  11\n",
      "dim_6                  11\n",
      "dim_7                  11\n",
      "dim_8                  11\n",
      "dim_9                  11\n",
      "dim_10                 11\n",
      "dim_11                 11\n",
      "dim_12                 11\n",
      "dim_13                 11\n",
      "dim_14                 11\n",
      "dim_15                 11\n",
      "dim_16                 11\n",
      "dim_17                 11\n",
      "dim_18                 11\n",
      "dim_19                 11\n",
      "dim_20                 11\n",
      "dim_21                 11\n",
      "dim_22                 11\n",
      "dim_23                 11\n",
      "dim_24                 11\n",
      "dim_25                 11\n",
      "dim_26                 11\n",
      "dim_27                 11\n",
      "dim_28                 11\n",
      "dim_29                 11\n",
      "dim_30                 11\n",
      "dim_31                 11\n",
      "dim_32                 11\n",
      "dim_33                 11\n",
      "dim_34                 11\n",
      "dim_35                 11\n",
      "dim_36                 11\n",
      "dim_37                 11\n",
      "dim_38                 11\n",
      "dim_39                 11\n",
      "dim_40                 11\n",
      "dim_41                 11\n",
      "dim_42                 11\n",
      "dim_43                 11\n",
      "dim_44                 11\n",
      "dim_45                 11\n",
      "dim_46                 11\n",
      "dim_47                 11\n",
      "dim_48                 11\n",
      "dim_49                 11\n",
      "dim_50                 11\n",
      "dim_51                 11\n",
      "dim_52                 11\n",
      "dim_53                 11\n",
      "dim_54                 11\n",
      "dim_55                 11\n",
      "dim_56                 11\n",
      "dim_57                 11\n",
      "dim_58                 11\n",
      "dim_59                 11\n",
      "dim_60                 11\n",
      "dim_61                 11\n",
      "dim_62                 11\n",
      "dim_63                 11\n",
      "dim_64                 11\n",
      "dim_65                 11\n",
      "dim_66                 11\n",
      "dim_67                 11\n",
      "dim_68                 11\n",
      "dim_69                 11\n",
      "dim_70                 11\n",
      "dim_71                 11\n",
      "dim_72                 11\n",
      "dim_73                 11\n",
      "dim_74                 11\n",
      "dim_75                 11\n",
      "dim_76                 11\n",
      "dim_77                 11\n",
      "dim_78                 11\n",
      "dim_79                 11\n",
      "dim_80                 11\n",
      "dim_81                 11\n",
      "dim_82                 11\n",
      "dim_83                 11\n",
      "dim_84                 11\n",
      "dim_85                 11\n",
      "dim_86                 11\n",
      "dim_87                 11\n",
      "dim_88                 11\n",
      "dim_89                 11\n",
      "dim_90                 11\n",
      "dim_91                 11\n",
      "dim_92                 11\n",
      "dim_93                 11\n",
      "dim_94                 11\n",
      "dim_95                 11\n",
      "dim_96                 11\n",
      "dim_97                 11\n",
      "dim_98                 11\n",
      "dim_99                 11\n",
      "dim_100                11\n",
      "dim_101                11\n",
      "dim_102                11\n",
      "dim_103                11\n",
      "dim_104                11\n",
      "dim_105                11\n",
      "dim_106                11\n",
      "dim_107                11\n",
      "dim_108                11\n",
      "dim_109                11\n",
      "dim_110                11\n",
      "dim_111                11\n",
      "dim_112                11\n",
      "dim_113                11\n",
      "dim_114                11\n",
      "dim_115                11\n",
      "dim_116                11\n",
      "dim_117                11\n",
      "dim_118                11\n",
      "dim_119                11\n",
      "dim_120                11\n",
      "dim_121                11\n",
      "dim_122                11\n",
      "dim_123                11\n",
      "dim_124                11\n",
      "dim_125                11\n",
      "dim_126                11\n",
      "dim_127                11\n",
      "dim_128                11\n",
      "dim_129                11\n",
      "dim_130                11\n",
      "dim_131                11\n",
      "dim_132                11\n",
      "dim_133                11\n",
      "dim_134                11\n",
      "dim_135                11\n",
      "dim_136                11\n",
      "dim_137                11\n",
      "dim_138                11\n",
      "dim_139                11\n",
      "dim_140                11\n",
      "dim_141                11\n",
      "dim_142                11\n",
      "dim_143                11\n",
      "dim_144                11\n",
      "dim_145                11\n",
      "dim_146                11\n",
      "dim_147                11\n",
      "dim_148                11\n",
      "dim_149                11\n",
      "dim_150                11\n",
      "dim_151                11\n",
      "dim_152                11\n",
      "dim_153                11\n",
      "dim_154                11\n",
      "dim_155                11\n",
      "dim_156                11\n",
      "dim_157                11\n",
      "dim_158                11\n",
      "dim_159                11\n",
      "dim_160                11\n",
      "dim_161                11\n",
      "dim_162                11\n",
      "dim_163                11\n",
      "dim_164                11\n",
      "dim_165                11\n",
      "dim_166                11\n",
      "dim_167                11\n",
      "dim_168                11\n",
      "dim_169                11\n",
      "dim_170                11\n",
      "dim_171                11\n",
      "dim_172                11\n",
      "dim_173                11\n",
      "dim_174                11\n",
      "dim_175                11\n",
      "dim_176                11\n",
      "dim_177                11\n",
      "dim_178                11\n",
      "dim_179                11\n",
      "dim_180                11\n",
      "dim_181                11\n",
      "dim_182                11\n",
      "dim_183                11\n",
      "dim_184                11\n",
      "dim_185                11\n",
      "dim_186                11\n",
      "dim_187                11\n",
      "dim_188                11\n",
      "dim_189                11\n",
      "dim_190                11\n",
      "dim_191                11\n",
      "dim_192                11\n",
      "dim_193                11\n",
      "dim_194                11\n",
      "dim_195                11\n",
      "dim_196                11\n",
      "dim_197                11\n",
      "dim_198                11\n",
      "dim_199                11\n",
      "dim_200                11\n",
      "dim_201                11\n",
      "dim_202                11\n",
      "dim_203                11\n",
      "dim_204                11\n",
      "dim_205                11\n",
      "dim_206                11\n",
      "dim_207                11\n",
      "dim_208                11\n",
      "dim_209                11\n",
      "dim_210                11\n",
      "dim_211                11\n",
      "dim_212                11\n",
      "dim_213                11\n",
      "dim_214                11\n",
      "dim_215                11\n",
      "dim_216                11\n",
      "dim_217                11\n",
      "dim_218                11\n",
      "dim_219                11\n",
      "dim_220                11\n",
      "dim_221                11\n",
      "dim_222                11\n",
      "dim_223                11\n",
      "dim_224                11\n",
      "dim_225                11\n",
      "dim_226                11\n",
      "dim_227                11\n",
      "dim_228                11\n",
      "dim_229                11\n",
      "dim_230                11\n",
      "dim_231                11\n",
      "dim_232                11\n",
      "dim_233                11\n",
      "dim_234                11\n",
      "dim_235                11\n",
      "dim_236                11\n",
      "dim_237                11\n",
      "dim_238                11\n",
      "dim_239                11\n",
      "dim_240                11\n",
      "dim_241                11\n",
      "dim_242                11\n",
      "dim_243                11\n",
      "dim_244                11\n",
      "dim_245                11\n",
      "dim_246                11\n",
      "dim_247                11\n",
      "dim_248                11\n",
      "dim_249                11\n",
      "dim_250                11\n",
      "dim_251                11\n",
      "dim_252                11\n",
      "dim_253                11\n",
      "dim_254                11\n",
      "dim_255                11\n",
      "dim_256                11\n",
      "dim_257                11\n",
      "dim_258                11\n",
      "dim_259                11\n",
      "dim_260                11\n",
      "dim_261                11\n",
      "dim_262                11\n",
      "dim_263                11\n",
      "dim_264                11\n",
      "dim_265                11\n",
      "dim_266                11\n",
      "dim_267                11\n",
      "dim_268                11\n",
      "dim_269                11\n",
      "dim_270                11\n",
      "dim_271                11\n",
      "dim_272                11\n",
      "dim_273                11\n",
      "dim_274                11\n",
      "dim_275                11\n",
      "dim_276                11\n",
      "dim_277                11\n",
      "dim_278                11\n",
      "dim_279                11\n",
      "dim_280                11\n",
      "dim_281                11\n",
      "dim_282                11\n",
      "dim_283                11\n",
      "dim_284                11\n",
      "dim_285                11\n",
      "dim_286                11\n",
      "dim_287                11\n",
      "dim_288                11\n",
      "dim_289                11\n",
      "dim_290                11\n",
      "dim_291                11\n",
      "dim_292                11\n",
      "dim_293                11\n",
      "dim_294                11\n",
      "dim_295                11\n",
      "dim_296                11\n",
      "dim_297                11\n",
      "dim_298                11\n",
      "dim_299                11\n",
      "dim_300                11\n",
      "dim_301                11\n",
      "dim_302                11\n",
      "dim_303                11\n",
      "dim_304                11\n",
      "dim_305                11\n",
      "dim_306                11\n",
      "dim_307                11\n",
      "dim_308                11\n",
      "dim_309                11\n",
      "dim_310                11\n",
      "dim_311                11\n",
      "dim_312                11\n",
      "dim_313                11\n",
      "dim_314                11\n",
      "dim_315                11\n",
      "dim_316                11\n",
      "dim_317                11\n",
      "dim_318                11\n",
      "dim_319                11\n",
      "dim_320                11\n",
      "dim_321                11\n",
      "dim_322                11\n",
      "dim_323                11\n",
      "dim_324                11\n",
      "dim_325                11\n",
      "dim_326                11\n",
      "dim_327                11\n",
      "dim_328                11\n",
      "dim_329                11\n",
      "dim_330                11\n",
      "dim_331                11\n",
      "dim_332                11\n",
      "dim_333                11\n",
      "dim_334                11\n",
      "dim_335                11\n",
      "dim_336                11\n",
      "dim_337                11\n",
      "dim_338                11\n",
      "dim_339                11\n",
      "dim_340                11\n",
      "dim_341                11\n",
      "dim_342                11\n",
      "dim_343                11\n",
      "dim_344                11\n",
      "dim_345                11\n",
      "dim_346                11\n",
      "dim_347                11\n",
      "dim_348                11\n",
      "dim_349                11\n",
      "dim_350                11\n",
      "dim_351                11\n",
      "dim_352                11\n",
      "dim_353                11\n",
      "dim_354                11\n",
      "dim_355                11\n",
      "dim_356                11\n",
      "dim_357                11\n",
      "dim_358                11\n",
      "dim_359                11\n",
      "dim_360                11\n",
      "dim_361                11\n",
      "dim_362                11\n",
      "dim_363                11\n",
      "dim_364                11\n",
      "dim_365                11\n",
      "dim_366                11\n",
      "dim_367                11\n",
      "dim_368                11\n",
      "dim_369                11\n",
      "dim_370                11\n",
      "dim_371                11\n",
      "dim_372                11\n",
      "dim_373                11\n",
      "dim_374                11\n",
      "dim_375                11\n",
      "dim_376                11\n",
      "dim_377                11\n",
      "dim_378                11\n",
      "dim_379                11\n",
      "dim_380                11\n",
      "dim_381                11\n",
      "dim_382                11\n",
      "dim_383                11\n",
      "dim_384                11\n",
      "dim_385                11\n",
      "dim_386                11\n",
      "dim_387                11\n",
      "dim_388                11\n",
      "dim_389                11\n",
      "dim_390                11\n",
      "dim_391                11\n",
      "dim_392                11\n",
      "dim_393                11\n",
      "dim_394                11\n",
      "dim_395                11\n",
      "dim_396                11\n",
      "dim_397                11\n",
      "dim_398                11\n",
      "dim_399                11\n",
      "dim_400                11\n",
      "dim_401                11\n",
      "dim_402                11\n",
      "dim_403                11\n",
      "dim_404                11\n",
      "dim_405                11\n",
      "dim_406                11\n",
      "dim_407                11\n",
      "dim_408                11\n",
      "dim_409                11\n",
      "dim_410                11\n",
      "dim_411                11\n",
      "dim_412                11\n",
      "dim_413                11\n",
      "dim_414                11\n",
      "dim_415                11\n",
      "dim_416                11\n",
      "dim_417                11\n",
      "dim_418                11\n",
      "dim_419                11\n",
      "dim_420                11\n",
      "dim_421                11\n",
      "dim_422                11\n",
      "dim_423                11\n",
      "dim_424                11\n",
      "dim_425                11\n",
      "dim_426                11\n",
      "dim_427                11\n",
      "dim_428                11\n",
      "dim_429                11\n",
      "dim_430                11\n",
      "dim_431                11\n",
      "dim_432                11\n",
      "dim_433                11\n",
      "dim_434                11\n",
      "dim_435                11\n",
      "dim_436                11\n",
      "dim_437                11\n",
      "dim_438                11\n",
      "dim_439                11\n",
      "dim_440                11\n",
      "dim_441                11\n",
      "dim_442                11\n",
      "dim_443                11\n",
      "dim_444                11\n",
      "dim_445                11\n",
      "dim_446                11\n",
      "dim_447                11\n",
      "dim_448                11\n",
      "dim_449                11\n",
      "dim_450                11\n",
      "dim_451                11\n",
      "dim_452                11\n",
      "dim_453                11\n",
      "dim_454                11\n",
      "dim_455                11\n",
      "dim_456                11\n",
      "dim_457                11\n",
      "dim_458                11\n",
      "dim_459                11\n",
      "dim_460                11\n",
      "dim_461                11\n",
      "dim_462                11\n",
      "dim_463                11\n",
      "dim_464                11\n",
      "dim_465                11\n",
      "dim_466                11\n",
      "dim_467                11\n",
      "dim_468                11\n",
      "dim_469                11\n",
      "dim_470                11\n",
      "dim_471                11\n",
      "dim_472                11\n",
      "dim_473                11\n",
      "dim_474                11\n",
      "dim_475                11\n",
      "dim_476                11\n",
      "dim_477                11\n",
      "dim_478                11\n",
      "dim_479                11\n",
      "dim_480                11\n",
      "dim_481                11\n",
      "dim_482                11\n",
      "dim_483                11\n",
      "dim_484                11\n",
      "dim_485                11\n",
      "dim_486                11\n",
      "dim_487                11\n",
      "dim_488                11\n",
      "dim_489                11\n",
      "dim_490                11\n",
      "dim_491                11\n",
      "dim_492                11\n",
      "dim_493                11\n",
      "dim_494                11\n",
      "dim_495                11\n",
      "dim_496                11\n",
      "dim_497                11\n",
      "dim_498                11\n",
      "dim_499                11\n",
      "dim_500                11\n",
      "dim_501                11\n",
      "dim_502                11\n",
      "dim_503                11\n",
      "dim_504                11\n",
      "dim_505                11\n",
      "dim_506                11\n",
      "dim_507                11\n",
      "dim_508                11\n",
      "dim_509                11\n",
      "dim_510                11\n",
      "dim_511                11\n",
      "dim_512                11\n",
      "dim_513                11\n",
      "dim_514                11\n",
      "dim_515                11\n",
      "dim_516                11\n",
      "dim_517                11\n",
      "dim_518                11\n",
      "dim_519                11\n",
      "dim_520                11\n",
      "dim_521                11\n",
      "dim_522                11\n",
      "dim_523                11\n",
      "dim_524                11\n",
      "dim_525                11\n",
      "dim_526                11\n",
      "dim_527                11\n",
      "dim_528                11\n",
      "dim_529                11\n",
      "dim_530                11\n",
      "dim_531                11\n",
      "dim_532                11\n",
      "dim_533                11\n",
      "dim_534                11\n",
      "dim_535                11\n",
      "dim_536                11\n",
      "dim_537                11\n",
      "dim_538                11\n",
      "dim_539                11\n",
      "dim_540                11\n",
      "dim_541                11\n",
      "dim_542                11\n",
      "dim_543                11\n",
      "dim_544                11\n",
      "dim_545                11\n",
      "dim_546                11\n",
      "dim_547                11\n",
      "dim_548                11\n",
      "dim_549                11\n",
      "dim_550                11\n",
      "dim_551                11\n",
      "dim_552                11\n",
      "dim_553                11\n",
      "dim_554                11\n",
      "dim_555                11\n",
      "dim_556                11\n",
      "dim_557                11\n",
      "dim_558                11\n",
      "dim_559                11\n",
      "dim_560                11\n",
      "dim_561                11\n",
      "dim_562                11\n",
      "dim_563                11\n",
      "dim_564                11\n",
      "dim_565                11\n",
      "dim_566                11\n",
      "dim_567                11\n",
      "dim_568                11\n",
      "dim_569                11\n",
      "dim_570                11\n",
      "dim_571                11\n",
      "dim_572                11\n",
      "dim_573                11\n",
      "dim_574                11\n",
      "dim_575                11\n",
      "dim_576                11\n",
      "dim_577                11\n",
      "dim_578                11\n",
      "dim_579                11\n",
      "dim_580                11\n",
      "dim_581                11\n",
      "dim_582                11\n",
      "dim_583                11\n",
      "dim_584                11\n",
      "dim_585                11\n",
      "dim_586                11\n",
      "dim_587                11\n",
      "dim_588                11\n",
      "dim_589                11\n",
      "dim_590                11\n",
      "dim_591                11\n",
      "dim_592                11\n",
      "dim_593                11\n",
      "dim_594                11\n",
      "dim_595                11\n",
      "dim_596                11\n",
      "dim_597                11\n",
      "dim_598                11\n",
      "dim_599                11\n",
      "dim_600                11\n",
      "dim_601                11\n",
      "dim_602                11\n",
      "dim_603                11\n",
      "dim_604                11\n",
      "dim_605                11\n",
      "dim_606                11\n",
      "dim_607                11\n",
      "dim_608                11\n",
      "dim_609                11\n",
      "dim_610                11\n",
      "dim_611                11\n",
      "dim_612                11\n",
      "dim_613                11\n",
      "dim_614                11\n",
      "dim_615                11\n",
      "dim_616                11\n",
      "dim_617                11\n",
      "dim_618                11\n",
      "dim_619                11\n",
      "dim_620                11\n",
      "dim_621                11\n",
      "dim_622                11\n",
      "dim_623                11\n",
      "dim_624                11\n",
      "dim_625                11\n",
      "dim_626                11\n",
      "dim_627                11\n",
      "dim_628                11\n",
      "dim_629                11\n",
      "dim_630                11\n",
      "dim_631                11\n",
      "dim_632                11\n",
      "dim_633                11\n",
      "dim_634                11\n",
      "dim_635                11\n",
      "dim_636                11\n",
      "dim_637                11\n",
      "dim_638                11\n",
      "dim_639                11\n",
      "dim_640                11\n",
      "dim_641                11\n",
      "dim_642                11\n",
      "dim_643                11\n",
      "dim_644                11\n",
      "dim_645                11\n",
      "dim_646                11\n",
      "dim_647                11\n",
      "dim_648                11\n",
      "dim_649                11\n",
      "dim_650                11\n",
      "dim_651                11\n",
      "dim_652                11\n",
      "dim_653                11\n",
      "dim_654                11\n",
      "dim_655                11\n",
      "dim_656                11\n",
      "dim_657                11\n",
      "dim_658                11\n",
      "dim_659                11\n",
      "dim_660                11\n",
      "dim_661                11\n",
      "dim_662                11\n",
      "dim_663                11\n",
      "dim_664                11\n",
      "dim_665                11\n",
      "dim_666                11\n",
      "dim_667                11\n",
      "dim_668                11\n",
      "dim_669                11\n",
      "dim_670                11\n",
      "dim_671                11\n",
      "dim_672                11\n",
      "dim_673                11\n",
      "dim_674                11\n",
      "dim_675                11\n",
      "dim_676                11\n",
      "dim_677                11\n",
      "dim_678                11\n",
      "dim_679                11\n",
      "dim_680                11\n",
      "dim_681                11\n",
      "dim_682                11\n",
      "dim_683                11\n",
      "dim_684                11\n",
      "dim_685                11\n",
      "dim_686                11\n",
      "dim_687                11\n",
      "dim_688                11\n",
      "dim_689                11\n",
      "dim_690                11\n",
      "dim_691                11\n",
      "dim_692                11\n",
      "dim_693                11\n",
      "dim_694                11\n",
      "dim_695                11\n",
      "dim_696                11\n",
      "dim_697                11\n",
      "dim_698                11\n",
      "dim_699                11\n",
      "dim_700                11\n",
      "dim_701                11\n",
      "dim_702                11\n",
      "dim_703                11\n",
      "dim_704                11\n",
      "dim_705                11\n",
      "dim_706                11\n",
      "dim_707                11\n",
      "dim_708                11\n",
      "dim_709                11\n",
      "dim_710                11\n",
      "dim_711                11\n",
      "dim_712                11\n",
      "dim_713                11\n",
      "dim_714                11\n",
      "dim_715                11\n",
      "dim_716                11\n",
      "dim_717                11\n",
      "dim_718                11\n",
      "dim_719                11\n",
      "dim_720                11\n",
      "dim_721                11\n",
      "dim_722                11\n",
      "dim_723                11\n",
      "dim_724                11\n",
      "dim_725                11\n",
      "dim_726                11\n",
      "dim_727                11\n",
      "dim_728                11\n",
      "dim_729                11\n",
      "dim_730                11\n",
      "dim_731                11\n",
      "dim_732                11\n",
      "dim_733                11\n",
      "dim_734                11\n",
      "dim_735                11\n",
      "dim_736                11\n",
      "dim_737                11\n",
      "dim_738                11\n",
      "dim_739                11\n",
      "dim_740                11\n",
      "dim_741                11\n",
      "dim_742                11\n",
      "dim_743                11\n",
      "dim_744                11\n",
      "dim_745                11\n",
      "dim_746                11\n",
      "dim_747                11\n",
      "dim_748                11\n",
      "dim_749                11\n",
      "dim_750                11\n",
      "dim_751                11\n",
      "dim_752                11\n",
      "dim_753                11\n",
      "dim_754                11\n",
      "dim_755                11\n",
      "dim_756                11\n",
      "dim_757                11\n",
      "dim_758                11\n",
      "dim_759                11\n",
      "dim_760                11\n",
      "dim_761                11\n",
      "dim_762                11\n",
      "dim_763                11\n",
      "dim_764                11\n",
      "dim_765                11\n",
      "dim_766                11\n",
      "dim_767                11\n",
      "\n",
      "We recommend preprocessing discrete columns that can have many values, using 'update_transformers'. Or you may drop columns that are not necessary to model. (Exit this script using ctrl-C)\n",
      "\n",
      "Generando 1979 muestras sintéticas...\n",
      "\n",
      "Distribución de sub-categorías DESPUÉS del aumento:\n",
      "sub_label_str\n",
      "Race                   639\n",
      "Sexual Orientation     577\n",
      "Gender                 447\n",
      "Class                  179\n",
      "Behavior               185\n",
      "Ethnicity              200\n",
      "Physical Appearance    266\n",
      "Disability             201\n",
      "Religion               195\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"--- Preparando datos para aumento ---\")\n",
    "# 1. Aislar los datos de entrenamiento que son 'odio'\n",
    "df_train_hate = df_train[df_train['main_label'] == 1].copy()\n",
    "features_to_augment = ['sub_label_str'] + embedding_cols\n",
    "df_to_augment = df_train_hate[features_to_augment]\n",
    "\n",
    "print(\"Distribución de sub-categorías ANTES del aumento:\")\n",
    "hate_counts = df_to_augment['sub_label_str'].value_counts()\n",
    "print(hate_counts)\n",
    "\n",
    "# Crear un nuevo encoder dedicado SOLO para las sub-categorías de odio.\n",
    "sub_hate_only_encoder = LabelEncoder()\n",
    "\n",
    "if len(hate_counts) > 1 and not df_to_augment.empty:\n",
    "    # Ajustar el nuevo encoder solo con las etiquetas de odio\n",
    "    sub_hate_only_encoder.fit(df_to_augment['sub_label_str'])\n",
    "    print(\"\\nNuevo encoder para Nivel 2 creado. Clases:\", sub_hate_only_encoder.classes_)\n",
    "    \n",
    "    # 2. Configurar metadatos\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=df_to_augment)\n",
    "    \n",
    "    print(\"\\nActualizando metadatos para tratar embeddings como numéricos continuos...\")\n",
    "    for col in embedding_cols:\n",
    "        metadata.update_column(column_name=col, sdtype='numerical')\n",
    "    metadata.update_column(column_name='sub_label_str', sdtype='categorical')\n",
    "\n",
    "    # 3. Configurar y entrenar el sintetizador CTGAN\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    print(f\"Usando GPU: {use_gpu}\")\n",
    "    synthesizer = CTGANSynthesizer(\n",
    "        metadata, \n",
    "        epochs=150, \n",
    "        embedding_dim=64, \n",
    "        verbose=False,\n",
    "        cuda=use_gpu  \n",
    "    )\n",
    "    \n",
    "    print(f\"\\nEntrenando CTGAN para generar datos sintéticos... (Usando GPU: {use_gpu})\")\n",
    "    synthesizer.fit(df_to_augment)\n",
    "\n",
    "    # 4. Determinar cuántas muestras generar\n",
    "    max_class_size = hate_counts.max()\n",
    "    num_to_generate = max_class_size * len(hate_counts) - hate_counts.sum()\n",
    "\n",
    "    # 5. Generar y combinar datos\n",
    "    if num_to_generate > 0:\n",
    "        print(f\"\\nGenerando {num_to_generate} muestras sintéticas...\")\n",
    "        df_synthetic = synthesizer.sample(num_rows=num_to_generate)\n",
    "        df_train_hate_balanced = pd.concat([df_to_augment, df_synthetic], ignore_index=True)\n",
    "    else:\n",
    "        df_train_hate_balanced = df_to_augment\n",
    "else:\n",
    "    print(\"\\nSolo una sub-categoría presente o no hay datos de odio, no se requiere aumento.\")\n",
    "    df_train_hate_balanced = df_to_augment\n",
    "    if not df_to_augment.empty:\n",
    "        # Ajustar el encoder si solo hay una clase\n",
    "        sub_hate_only_encoder.fit(df_to_augment['sub_label_str'])\n",
    "\n",
    "print(\"\\nDistribución de sub-categorías DESPUÉS del aumento:\")\n",
    "all_sub_labels = df_to_augment['sub_label_str'].unique()\n",
    "print(df_train_hate_balanced['sub_label_str'].value_counts().reindex(all_sub_labels, fill_value=0))\n",
    "\n",
    "# Preparar datos de entrenamiento para el clasificador de sub-categorías\n",
    "if not df_train_hate_balanced.empty:\n",
    "    X_train_sub = df_train_hate_balanced[embedding_cols].values\n",
    "    # Usar el NUEVO encoder para transformar las etiquetas\n",
    "    y_train_sub = sub_hate_only_encoder.transform(df_train_hate_balanced['sub_label_str'])\n",
    "else:\n",
    "    # Crear arrays vacíos si no hay datos para evitar errores posteriores\n",
    "    X_train_sub = np.array([]).reshape(0, len(embedding_cols))\n",
    "    y_train_sub = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "main_classifier_md",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del Clasificador Principal (Nivel 1) con Optuna y Ensemble\n",
    "\n",
    "Aquí es donde integramos el pipeline de entrenamiento robusto. Entrenaremos y optimizaremos los cuatro modelos (XGBoost, MLP, y dos Regresiones Logísticas) para la tarea de clasificación binaria (Odio vs. No-Odio). Este proceso no utiliza los datos aumentados, solo el conjunto de entrenamiento original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_classifier_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparando datos para el entrenamiento del Clasificador Principal ---\n",
      "TF-IDF: 10000 características generadas.\n",
      "\n",
      "✓ Datos escalados, vectorizados y tensores de PyTorch listos para el Nivel 1.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"--- Preparando datos para el entrenamiento del Clasificador Principal ---\")\n",
    "\n",
    "# Usar las variables correctas del split jerárquico\n",
    "y_train = df_train['main_label'].values\n",
    "y_val = df_val['main_label'].values\n",
    "num_classes = len(np.unique(y_train)) # Será 2 en este caso\n",
    "\n",
    "# 1. Escalar características de embeddings\n",
    "scaler = StandardScaler()\n",
    "X_train_emb = df_train[embedding_cols].values\n",
    "X_train_emb_scaled = scaler.fit_transform(X_train_emb)\n",
    "X_val_emb = df_val[embedding_cols].values\n",
    "X_val_emb_scaled = scaler.transform(X_val_emb)\n",
    "\n",
    "# 2. Vectorizar características de texto con TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_text = df_train['text_stemmed'].values\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_val_text = df_val['text_stemmed'].values\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val_text)\n",
    "print(f\"TF-IDF: {X_train_tfidf.shape[1]} características generadas.\")\n",
    "\n",
    "# 3. Convertir datos de validación a tensores para PyTorch\n",
    "X_val_torch = torch.tensor(X_val_emb_scaled, dtype=torch.float32).to(device)\n",
    "y_val_torch = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "\n",
    "print(\"\\n✓ Datos escalados, vectorizados y tensores de PyTorch listos para el Nivel 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5533809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones objetivo de Optuna para el Nivel 1 definidas.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Objetivo para MLP con PyTorch (Usa Embeddings) ---\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size, activation_fn, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(current_size, hidden_size))\n",
    "            layers.append(activation_fn())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            current_size = hidden_size\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def objective_mlp(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    hidden_layers = [trial.suggest_int(f'n_units_l{i}', 32, 256) for i in range(n_layers)]\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop'])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    activation_fn = getattr(nn, trial.suggest_categorical('activation', ['ReLU', 'Tanh']))\n",
    "    \n",
    "    model = MLP(X_train_emb_scaled.shape[1], hidden_layers, num_classes, activation_fn, dropout_rate).to(device)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train_emb_scaled, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    for epoch in range(25): # Menos epochs para HPO más rápido\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(data), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = criterion(model(X_val_torch), y_val_torch).item()\n",
    "    \n",
    "    trial.report(val_loss, epoch)\n",
    "    if trial.should_prune(): raise optuna.exceptions.TrialPruned()\n",
    "    return val_loss\n",
    "\n",
    "# --- 2. Objetivo para XGBoost (Usa Embeddings) ---\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        'objective': 'binary:logistic' if num_classes == 2 else 'multi:softprob',\n",
    "        'eval_metric': 'logloss' if num_classes == 2 else 'mlogloss',\n",
    "        'device': 'cuda' if device.type == 'cuda' else 'cpu',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params, early_stopping_rounds=10)\n",
    "    model.fit(X_train_emb, y_train, eval_set=[(X_val_emb, y_val)], verbose=False)\n",
    "    return log_loss(y_val, model.predict_proba(X_val_emb))\n",
    "\n",
    "# --- 3. Objetivo para Regresión Logística (Usa Embeddings) ---\n",
    "def objective_logistic_embeddings(trial):\n",
    "    params = {'C': trial.suggest_float('C', 1e-4, 1e2, log=True), 'solver': 'liblinear', 'max_iter': 1000}\n",
    "    model = LogisticRegression(**params, random_state=42)\n",
    "    model.fit(X_train_emb_scaled, y_train)\n",
    "    return log_loss(y_val, model.predict_proba(X_val_emb_scaled))\n",
    "\n",
    "# --- 4. Objetivo para Regresión Logística (Usa TF-IDF) ---\n",
    "def objective_logistic_tfidf(trial):\n",
    "    params = {'C': trial.suggest_float('C', 1e-2, 1e2, log=True), 'solver': 'liblinear', 'max_iter': 1000}\n",
    "    model = LogisticRegression(**params, random_state=42)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    return log_loss(y_val, model.predict_proba(X_val_tfidf))\n",
    "\n",
    "print(f\"Funciones objetivo de Optuna para el Nivel 1 definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b520e155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:37:58,209] A new study created in memory with name: no-name-29223502-920d-428b-93bd-b7bf90b6ed07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizando XGBoost (Nivel 1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.388348:   4%|▍         | 1/25 [00:01<00:45,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:00,114] Trial 0 finished with value: 0.38834796796875687 and parameters: {'n_estimators': 437, 'learning_rate': 0.2536999076681772, 'max_depth': 8}. Best is trial 0 with value: 0.38834796796875687.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.330828:   8%|▊         | 2/25 [00:06<01:14,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:04,318] Trial 1 finished with value: 0.3308276993342611 and parameters: {'n_estimators': 639, 'learning_rate': 0.01700037298921102, 'max_depth': 4}. Best is trial 1 with value: 0.3308276993342611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.330828:  12%|█▏        | 3/25 [00:07<00:53,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:05,770] Trial 2 finished with value: 0.35457881385286627 and parameters: {'n_estimators': 152, 'learning_rate': 0.19030368381735815, 'max_depth': 7}. Best is trial 1 with value: 0.3308276993342611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.330828:  16%|█▌        | 4/25 [00:35<04:24, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:33,896] Trial 3 finished with value: 0.3635742502413637 and parameters: {'n_estimators': 737, 'learning_rate': 0.010725209743171996, 'max_depth': 9}. Best is trial 1 with value: 0.3308276993342611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  20%|██        | 5/25 [00:39<03:10,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:38,048] Trial 4 finished with value: 0.3283516402816501 and parameters: {'n_estimators': 850, 'learning_rate': 0.020589728197687916, 'max_depth': 4}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  24%|██▍       | 6/25 [00:44<02:32,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:43,176] Trial 5 finished with value: 0.3424010185363584 and parameters: {'n_estimators': 265, 'learning_rate': 0.028145092716060652, 'max_depth': 6}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  28%|██▊       | 7/25 [00:52<02:20,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:50,540] Trial 6 finished with value: 0.3547687649305162 and parameters: {'n_estimators': 489, 'learning_rate': 0.02692655251486473, 'max_depth': 7}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  32%|███▏      | 8/25 [00:55<01:45,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:53,216] Trial 7 finished with value: 0.3421056697542824 and parameters: {'n_estimators': 225, 'learning_rate': 0.027010527749605478, 'max_depth': 5}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  36%|███▌      | 9/25 [00:55<01:12,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:54,145] Trial 8 finished with value: 0.3347771775892681 and parameters: {'n_estimators': 510, 'learning_rate': 0.14447746112718687, 'max_depth': 4}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  40%|████      | 10/25 [00:57<00:52,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:55,350] Trial 9 finished with value: 0.3349609370112823 and parameters: {'n_estimators': 563, 'learning_rate': 0.07500118950416987, 'max_depth': 3}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  44%|████▍     | 11/25 [00:58<00:38,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:38:56,344] Trial 10 finished with value: 0.3396220915620309 and parameters: {'n_estimators': 981, 'learning_rate': 0.06690992453172917, 'max_depth': 3}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  48%|████▊     | 12/25 [01:06<00:58,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:04,781] Trial 11 finished with value: 0.33582109176999275 and parameters: {'n_estimators': 847, 'learning_rate': 0.010464817979692459, 'max_depth': 5}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.328352:  52%|█████▏    | 13/25 [01:11<00:54,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:09,455] Trial 12 finished with value: 0.3310297457642165 and parameters: {'n_estimators': 710, 'learning_rate': 0.018042210081692857, 'max_depth': 4}. Best is trial 4 with value: 0.3283516402816501.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  56%|█████▌    | 14/25 [01:13<00:42,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:11,743] Trial 13 finished with value: 0.327103316371309 and parameters: {'n_estimators': 997, 'learning_rate': 0.04271369442805087, 'max_depth': 4}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  60%|██████    | 15/25 [01:16<00:35,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:14,426] Trial 14 finished with value: 0.3292267280214686 and parameters: {'n_estimators': 978, 'learning_rate': 0.04410047566419462, 'max_depth': 5}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  64%|██████▍   | 16/25 [01:17<00:25,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:15,846] Trial 15 finished with value: 0.3360596257760045 and parameters: {'n_estimators': 859, 'learning_rate': 0.044767771726731534, 'max_depth': 3}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  68%|██████▊   | 17/25 [01:19<00:20,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:17,567] Trial 16 finished with value: 0.341524444466647 and parameters: {'n_estimators': 851, 'learning_rate': 0.11124442632859347, 'max_depth': 6}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  72%|███████▏  | 18/25 [01:21<00:17,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:19,987] Trial 17 finished with value: 0.32880382190584445 and parameters: {'n_estimators': 999, 'learning_rate': 0.037451197538989976, 'max_depth': 4}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  76%|███████▌  | 19/25 [01:29<00:24,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:27,703] Trial 18 finished with value: 0.3435131842583088 and parameters: {'n_estimators': 795, 'learning_rate': 0.017250820550283107, 'max_depth': 6}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  80%|████████  | 20/25 [01:30<00:16,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:29,015] Trial 19 finished with value: 0.332489871213085 and parameters: {'n_estimators': 927, 'learning_rate': 0.09154387249271213, 'max_depth': 5}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  84%|████████▍ | 21/25 [01:31<00:10,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:30,187] Trial 20 finished with value: 0.34187274331030476 and parameters: {'n_estimators': 377, 'learning_rate': 0.05547535231708596, 'max_depth': 3}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  88%|████████▊ | 22/25 [01:34<00:07,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:32,267] Trial 21 finished with value: 0.3295852792436287 and parameters: {'n_estimators': 997, 'learning_rate': 0.036712507316242, 'max_depth': 4}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  92%|█████████▏| 23/25 [01:36<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:34,606] Trial 22 finished with value: 0.3294519604453533 and parameters: {'n_estimators': 898, 'learning_rate': 0.03366151211963755, 'max_depth': 4}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103:  96%|█████████▌| 24/25 [01:40<00:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:38,252] Trial 23 finished with value: 0.32791301563696784 and parameters: {'n_estimators': 784, 'learning_rate': 0.02114521057583463, 'max_depth': 4}. Best is trial 13 with value: 0.327103316371309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327103: 100%|██████████| 25/25 [01:46<00:00,  4.26s/it]\n",
      "[I 2025-06-25 01:39:44,786] A new study created in memory with name: no-name-fbcb44b0-bfd5-4192-84f4-879ddca085c7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:44,777] Trial 24 finished with value: 0.3344977433278849 and parameters: {'n_estimators': 749, 'learning_rate': 0.01493805762572708, 'max_depth': 5}. Best is trial 13 with value: 0.327103316371309.\n",
      "✓ XGBoost completado. Mejor LogLoss: 0.3271\n",
      "\n",
      "--- Optimizando MLP_PyTorch (Nivel 1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.37968:   3%|▎         | 1/30 [00:01<00:49,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:46,482] Trial 0 finished with value: 0.3796803057193756 and parameters: {'n_layers': 2, 'n_units_l0': 245, 'n_units_l1': 196, 'dropout_rate': 0.3394633936788146, 'optimizer': 'Adam', 'lr': 1.493656855461762e-05, 'activation': 'ReLU'}. Best is trial 0 with value: 0.3796803057193756.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.342347:   7%|▋         | 2/30 [00:03<00:47,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:48,151] Trial 1 finished with value: 0.34234651923179626 and parameters: {'n_layers': 3, 'n_units_l0': 36, 'n_units_l1': 250, 'n_units_l2': 219, 'dropout_rate': 0.18493564427131048, 'optimizer': 'RMSprop', 'lr': 8.17949947521167e-05, 'activation': 'ReLU'}. Best is trial 1 with value: 0.34234651923179626.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.342347:  10%|█         | 3/30 [00:04<00:42,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:49,581] Trial 2 finished with value: 0.37580549716949463 and parameters: {'n_layers': 1, 'n_units_l0': 169, 'dropout_rate': 0.15579754426081674, 'optimizer': 'RMSprop', 'lr': 0.00023345864076016249, 'activation': 'ReLU'}. Best is trial 1 with value: 0.34234651923179626.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.342347:  13%|█▎        | 4/30 [00:06<00:44,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:51,497] Trial 3 finished with value: 0.9165170192718506 and parameters: {'n_layers': 2, 'n_units_l0': 165, 'n_units_l1': 42, 'dropout_rate': 0.34301794076057535, 'optimizer': 'Adam', 'lr': 0.007025166339242158, 'activation': 'ReLU'}. Best is trial 1 with value: 0.34234651923179626.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.318321:  17%|█▋        | 5/30 [00:08<00:40,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:52,997] Trial 4 finished with value: 0.3183211088180542 and parameters: {'n_layers': 1, 'n_units_l0': 53, 'dropout_rate': 0.3736932106048628, 'optimizer': 'Adam', 'lr': 0.0003058656666978527, 'activation': 'Tanh'}. Best is trial 4 with value: 0.3183211088180542.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  20%|██        | 6/30 [00:09<00:38,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:54,503] Trial 5 finished with value: 0.3112765848636627 and parameters: {'n_layers': 1, 'n_units_l0': 181, 'dropout_rate': 0.2246844304357644, 'optimizer': 'RMSprop', 'lr': 3.585612610345396e-05, 'activation': 'ReLU'}. Best is trial 5 with value: 0.3112765848636627.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  23%|██▎       | 7/30 [00:11<00:38,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:56,296] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  27%|██▋       | 8/30 [00:13<00:38,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:58,178] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  30%|███       | 9/30 [00:14<00:33,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:39:59,551] Trial 8 finished with value: 0.3501242399215698 and parameters: {'n_layers': 1, 'n_units_l0': 215, 'dropout_rate': 0.38274293753904687, 'optimizer': 'RMSprop', 'lr': 1.667761543019792e-05, 'activation': 'ReLU'}. Best is trial 5 with value: 0.3112765848636627.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  33%|███▎      | 10/30 [00:16<00:33,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:01,351] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  37%|███▋      | 11/30 [00:18<00:31,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:03,000] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  40%|████      | 12/30 [00:19<00:29,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:04,633] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  43%|████▎     | 13/30 [00:21<00:28,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:06,299] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  47%|████▋     | 14/30 [00:23<00:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:07,847] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  50%|█████     | 15/30 [00:24<00:23,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:09,302] Trial 14 finished with value: 0.33943459391593933 and parameters: {'n_layers': 1, 'n_units_l0': 201, 'dropout_rate': 0.4505764863334542, 'optimizer': 'Adam', 'lr': 0.00023422328621630747, 'activation': 'Tanh'}. Best is trial 5 with value: 0.3112765848636627.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.311277:  53%|█████▎    | 16/30 [00:26<00:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:11,064] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  57%|█████▋    | 17/30 [00:28<00:21,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:12,804] Trial 16 finished with value: 0.30897584557533264 and parameters: {'n_layers': 1, 'n_units_l0': 76, 'dropout_rate': 0.24695155488800646, 'optimizer': 'RMSprop', 'lr': 0.00016006854792293955, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  60%|██████    | 18/30 [00:29<00:19,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:14,440] Trial 17 finished with value: 0.31004074215888977 and parameters: {'n_layers': 2, 'n_units_l0': 144, 'n_units_l1': 208, 'dropout_rate': 0.10263141366114917, 'optimizer': 'RMSprop', 'lr': 3.834304470038068e-05, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  63%|██████▎   | 19/30 [00:31<00:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:16,029] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  67%|██████▋   | 20/30 [00:32<00:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:17,729] Trial 19 finished with value: 0.33975961804389954 and parameters: {'n_layers': 2, 'n_units_l0': 134, 'n_units_l1': 138, 'dropout_rate': 0.2666349936722775, 'optimizer': 'RMSprop', 'lr': 0.000137501310114947, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  70%|███████   | 21/30 [00:34<00:15,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:19,505] Trial 20 finished with value: 0.3356916904449463 and parameters: {'n_layers': 2, 'n_units_l0': 84, 'n_units_l1': 211, 'dropout_rate': 0.11222606671483279, 'optimizer': 'RMSprop', 'lr': 2.53867069347109e-05, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  73%|███████▎  | 22/30 [00:36<00:13,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:21,045] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  77%|███████▋  | 23/30 [00:37<00:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:22,520] Trial 22 finished with value: 0.3257765471935272 and parameters: {'n_layers': 1, 'n_units_l0': 148, 'dropout_rate': 0.1913464841688231, 'optimizer': 'RMSprop', 'lr': 5.667717009082661e-05, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  80%|████████  | 24/30 [00:39<00:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:24,194] Trial 23 finished with value: 0.3190734088420868 and parameters: {'n_layers': 1, 'n_units_l0': 196, 'dropout_rate': 0.2637641985408664, 'optimizer': 'RMSprop', 'lr': 0.0001365793264765297, 'activation': 'ReLU'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  83%|████████▎ | 25/30 [00:41<00:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:26,131] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  87%|████████▋ | 26/30 [00:43<00:07,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:28,025] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  90%|█████████ | 27/30 [00:44<00:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:29,659] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 0.308976:  93%|█████████▎| 28/30 [00:46<00:03,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:31,686] Trial 27 finished with value: 0.31517887115478516 and parameters: {'n_layers': 3, 'n_units_l0': 256, 'n_units_l1': 222, 'n_units_l2': 43, 'dropout_rate': 0.1335174425080499, 'optimizer': 'RMSprop', 'lr': 2.0270997272903768e-05, 'activation': 'Tanh'}. Best is trial 16 with value: 0.30897584557533264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.306764:  97%|█████████▋| 29/30 [00:48<00:01,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:33,217] Trial 28 finished with value: 0.30676358938217163 and parameters: {'n_layers': 2, 'n_units_l0': 195, 'n_units_l1': 123, 'dropout_rate': 0.21081833311803883, 'optimizer': 'RMSprop', 'lr': 5.025034733267555e-05, 'activation': 'ReLU'}. Best is trial 28 with value: 0.30676358938217163.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 29. Best value: 0.302891: 100%|██████████| 30/30 [00:50<00:00,  1.67s/it]\n",
      "[I 2025-06-25 01:40:34,800] A new study created in memory with name: no-name-294506ed-6677-43dd-bfce-3debc93b9f35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:34,790] Trial 29 finished with value: 0.30289140343666077 and parameters: {'n_layers': 2, 'n_units_l0': 202, 'n_units_l1': 117, 'dropout_rate': 0.31366284922342336, 'optimizer': 'RMSprop', 'lr': 6.0160078144777785e-05, 'activation': 'ReLU'}. Best is trial 29 with value: 0.30289140343666077.\n",
      "✓ MLP_PyTorch completado. Mejor LogLoss: 0.3029\n",
      "\n",
      "--- Optimizando LogisticRegression_Embeddings (Nivel 1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:   5%|▌         | 1/20 [00:00<00:09,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:35,276] Trial 0 finished with value: 0.31922374641950113 and parameters: {'C': 0.017670169402947963}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  10%|█         | 2/20 [00:03<00:36,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:38,388] Trial 1 finished with value: 1.5955142482896418 and parameters: {'C': 50.61576888752309}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  15%|█▌        | 3/20 [00:05<00:31,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:40,022] Trial 2 finished with value: 0.8098998458689198 and parameters: {'C': 2.465832945854912}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  20%|██        | 4/20 [00:06<00:25,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:41,155] Trial 3 finished with value: 0.50440823117129 and parameters: {'C': 0.39079671568228835}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  25%|██▌       | 5/20 [00:06<00:16,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:41,372] Trial 4 finished with value: 0.4062108845720676 and parameters: {'C': 0.0008632008168602544}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  35%|███▌      | 7/20 [00:06<00:07,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:41,587] Trial 5 finished with value: 0.4062311119461451 and parameters: {'C': 0.0008629132190071859}. Best is trial 0 with value: 0.31922374641950113.\n",
      "[I 2025-06-25 01:40:41,724] Trial 6 finished with value: 0.49179866551459905 and parameters: {'C': 0.00022310108018679258}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  40%|████      | 8/20 [00:09<00:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:44,031] Trial 7 finished with value: 1.2866922738134148 and parameters: {'C': 15.741890047456648}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  45%|████▌     | 9/20 [00:10<00:12,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:45,202] Trial 8 finished with value: 0.5085943495265486 and parameters: {'C': 0.4042872735027334}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.319224:  50%|█████     | 10/20 [00:12<00:13,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:47,067] Trial 9 finished with value: 0.7405196393655641 and parameters: {'C': 1.7718847354806828}. Best is trial 0 with value: 0.31922374641950113.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.319215:  55%|█████▌    | 11/20 [00:12<00:09,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:47,587] Trial 10 finished with value: 0.31921511298162764 and parameters: {'C': 0.017654677164766052}. Best is trial 10 with value: 0.31921511298162764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.319215:  60%|██████    | 12/20 [00:13<00:07,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:48,070] Trial 11 finished with value: 0.31963801799006214 and parameters: {'C': 0.018388382022356858}. Best is trial 10 with value: 0.31921511298162764.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.31745:  65%|██████▌   | 13/20 [00:13<00:05,  1.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:48,542] Trial 12 finished with value: 0.3174502549962926 and parameters: {'C': 0.012798666702408415}. Best is trial 12 with value: 0.3174502549962926.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428:  70%|███████   | 14/20 [00:14<00:04,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:48,971] Trial 13 finished with value: 0.31742845333408026 and parameters: {'C': 0.012053282859112415}. Best is trial 13 with value: 0.31742845333408026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428:  75%|███████▌  | 15/20 [00:14<00:02,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:49,318] Trial 14 finished with value: 0.345137252213233 and parameters: {'C': 0.0028718250465162133}. Best is trial 13 with value: 0.31742845333408026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428:  80%|████████  | 16/20 [00:15<00:02,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:50,085] Trial 15 finished with value: 0.3535279019185097 and parameters: {'C': 0.061296196372412286}. Best is trial 13 with value: 0.31742845333408026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428:  85%|████████▌ | 17/20 [00:15<00:01,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:50,418] Trial 16 finished with value: 0.338999567018194 and parameters: {'C': 0.003409264942037956}. Best is trial 13 with value: 0.31742845333408026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428:  90%|█████████ | 18/20 [00:16<00:01,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:51,314] Trial 17 finished with value: 0.3731334741878992 and parameters: {'C': 0.08901581332229032}. Best is trial 13 with value: 0.31742845333408026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.317428: 100%|██████████| 20/20 [00:17<00:00,  1.17it/s]\n",
      "[I 2025-06-25 01:40:51,866] A new study created in memory with name: no-name-a40234a1-c907-4a16-a5cf-642ad3066311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:51,702] Trial 18 finished with value: 0.33286536853181986 and parameters: {'C': 0.00415403421342495}. Best is trial 13 with value: 0.31742845333408026.\n",
      "[I 2025-06-25 01:40:51,862] Trial 19 finished with value: 0.5296032502671237 and parameters: {'C': 0.00011996661220636725}. Best is trial 13 with value: 0.31742845333408026.\n",
      "✓ LogisticRegression_Embeddings completado. Mejor LogLoss: 0.3174\n",
      "\n",
      "--- Optimizando LogisticRegression_TFIDF (Nivel 1) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.183261:  35%|███▌      | 7/20 [00:00<00:00, 35.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:51,885] Trial 0 finished with value: 0.35527615580839433 and parameters: {'C': 0.31489116479568624}. Best is trial 0 with value: 0.35527615580839433.\n",
      "[I 2025-06-25 01:40:51,922] Trial 1 finished with value: 0.1924042412264549 and parameters: {'C': 63.512210106407046}. Best is trial 1 with value: 0.1924042412264549.\n",
      "[I 2025-06-25 01:40:51,953] Trial 2 finished with value: 0.18620053322128527 and parameters: {'C': 8.471801418819979}. Best is trial 2 with value: 0.18620053322128527.\n",
      "[I 2025-06-25 01:40:51,978] Trial 3 finished with value: 0.21830131127974442 and parameters: {'C': 2.481040974867813}. Best is trial 2 with value: 0.18620053322128527.\n",
      "[I 2025-06-25 01:40:51,992] Trial 4 finished with value: 0.5133252839930367 and parameters: {'C': 0.04207988669606638}. Best is trial 2 with value: 0.18620053322128527.\n",
      "[I 2025-06-25 01:40:52,006] Trial 5 finished with value: 0.5133373460531051 and parameters: {'C': 0.042070539502879395}. Best is trial 2 with value: 0.18620053322128527.\n",
      "[I 2025-06-25 01:40:52,008] Trial 6 finished with value: 0.5502256967712097 and parameters: {'C': 0.017073967431528128}. Best is trial 2 with value: 0.18620053322128527.\n",
      "[I 2025-06-25 01:40:52,049] Trial 7 finished with value: 0.18326064109811352 and parameters: {'C': 29.154431891537552}. Best is trial 7 with value: 0.18326064109811352.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:52,073] Trial 8 finished with value: 0.21739142624844643 and parameters: {'C': 2.5378155082656657}. Best is trial 7 with value: 0.18326064109811352.\n",
      "[I 2025-06-25 01:40:52,099] Trial 9 finished with value: 0.18956593831523136 and parameters: {'C': 6.79657809075816}. Best is trial 7 with value: 0.18326064109811352.\n",
      "[I 2025-06-25 01:40:52,136] Trial 10 finished with value: 0.19640185578666278 and parameters: {'C': 82.29631658321766}. Best is trial 7 with value: 0.18326064109811352.\n",
      "[I 2025-06-25 01:40:52,169] Trial 11 finished with value: 0.18159010722748264 and parameters: {'C': 20.996451336399733}. Best is trial 11 with value: 0.18159010722748264.\n",
      "[I 2025-06-25 01:40:52,201] Trial 12 finished with value: 0.18459080131066244 and parameters: {'C': 34.043053954671954}. Best is trial 11 with value: 0.18159010722748264.\n",
      "[I 2025-06-25 01:40:52,233] Trial 13 finished with value: 0.18140298496485857 and parameters: {'C': 17.14446414712941}. Best is trial 13 with value: 0.18140298496485857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 17. Best value: 0.181396: 100%|██████████| 20/20 [00:00<00:00, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:40:52,252] Trial 14 finished with value: 0.33732918864876865 and parameters: {'C': 0.3880040916855655}. Best is trial 13 with value: 0.18140298496485857.\n",
      "[I 2025-06-25 01:40:52,281] Trial 15 finished with value: 0.1836636745703452 and parameters: {'C': 10.66261287572915}. Best is trial 13 with value: 0.18140298496485857.\n",
      "[I 2025-06-25 01:40:52,304] Trial 16 finished with value: 0.27098679035802226 and parameters: {'C': 0.9253254956089687}. Best is trial 13 with value: 0.18140298496485857.\n",
      "[I 2025-06-25 01:40:52,334] Trial 17 finished with value: 0.18139642209754364 and parameters: {'C': 18.63934843098346}. Best is trial 17 with value: 0.18139642209754364.\n",
      "[I 2025-06-25 01:40:52,378] Trial 18 finished with value: 0.20862394501160347 and parameters: {'C': 3.217618717445632}. Best is trial 17 with value: 0.18139642209754364.\n",
      "[I 2025-06-25 01:40:52,414] Trial 19 finished with value: 0.19892671588852887 and parameters: {'C': 96.04396902719638}. Best is trial 17 with value: 0.18139642209754364.\n",
      "✓ LogisticRegression_TFIDF completado. Mejor LogLoss: 0.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models_config = {\n",
    "    'XGBoost': {'objective_func': objective_xgboost, 'n_trials': 25},\n",
    "    'MLP_PyTorch': {'objective_func': objective_mlp, 'n_trials': 30},\n",
    "    'LogisticRegression_Embeddings': {'objective_func': objective_logistic_embeddings, 'n_trials': 20},\n",
    "    'LogisticRegression_TFIDF': {'objective_func': objective_logistic_tfidf, 'n_trials': 20}\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name, config in models_config.items():\n",
    "    print(f\"\\n--- Optimizando {model_name} (Nivel 1) ---\")\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(config['objective_func'], n_trials=config['n_trials'], show_progress_bar=True)\n",
    "    \n",
    "    model_results[model_name] = {\n",
    "        'best_params': study.best_params,\n",
    "        'best_score': study.best_value\n",
    "    }\n",
    "    print(f\"✓ {model_name} completado. Mejor LogLoss: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5c4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entrenando modelos finales con los mejores hiperparámetros ---\n",
      "\n",
      "✓ Modelo XGBoost final entrenado.\n",
      "✓ Modelo Regresión Logística (Embeddings) final entrenado.\n",
      "✓ Modelo Regresión Logística (TF-IDF) final entrenado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs MLP final: 100%|██████████| 30/30 [00:01<00:00, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo MLP (PyTorch) final entrenado.\n",
      "\n",
      "✓ Todos los modelos finales han sido entrenados.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main_classifier_models = {} \n",
    "print(\"--- Entrenando modelos finales con los mejores hiperparámetros ---\\n\")\n",
    "\n",
    "# 1. XGBoost\n",
    "params = model_results['XGBoost']['best_params']\n",
    "final_xgb = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss',\n",
    "                              device='cuda' if device.type == 'cuda' else 'cpu',\n",
    "                              **params)\n",
    "final_xgb.fit(X_train_emb, y_train)\n",
    "main_classifier_models['XGBoost'] = final_xgb \n",
    "print(\"✓ Modelo XGBoost final entrenado.\")\n",
    "\n",
    "# 2. Regresión Logística (Embeddings)\n",
    "params = model_results['LogisticRegression_Embeddings']['best_params']\n",
    "final_log_emb = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000, **params)\n",
    "final_log_emb.fit(X_train_emb_scaled, y_train)\n",
    "main_classifier_models['LogisticRegression_Embeddings'] = final_log_emb # Usar el nuevo nombre de variable\n",
    "print(\"✓ Modelo Regresión Logística (Embeddings) final entrenado.\")\n",
    "\n",
    "# 3. Regresión Logística (TF-IDF)\n",
    "params = model_results['LogisticRegression_TFIDF']['best_params']\n",
    "final_log_tfidf = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000, **params)\n",
    "final_log_tfidf.fit(X_train_tfidf, y_train)\n",
    "main_classifier_models['LogisticRegression_TFIDF'] = final_log_tfidf # Usar el nuevo nombre de variable\n",
    "print(\"✓ Modelo Regresión Logística (TF-IDF) final entrenado.\")\n",
    "\n",
    "# 4. MLP (PyTorch)\n",
    "params = model_results['MLP_PyTorch']['best_params']\n",
    "hidden_layers = [params[f'n_units_l{i}'] for i in range(params['n_layers'])]\n",
    "final_mlp = MLP(input_size=X_train_emb_scaled.shape[1], hidden_layers=hidden_layers, output_size=num_classes, \n",
    "                activation_fn=getattr(nn, params['activation']), dropout_rate=params['dropout_rate']).to(device)\n",
    "optimizer = getattr(optim, params['optimizer'])(final_mlp.parameters(), lr=params['lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_emb_scaled, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "for epoch in tqdm(range(30), desc=\"Epochs MLP final\"):\n",
    "    final_mlp.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = final_mlp(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "main_classifier_models['MLP_PyTorch'] = final_mlp.eval() # Usar el nuevo nombre de variable\n",
    "print(\"✓ Modelo MLP (PyTorch) final entrenado.\")\n",
    "\n",
    "print(\"\\n✓ Todos los modelos finales han sido entrenados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32ef693a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculando pesos para el Ensemble del Clasificador Principal (Nivel 1) ---\n",
      "\n",
      "--- Pesos del Ensemble de Nivel 1 Calculados ---\n",
      "XGBoost                        | Peso: 0.187 | LogLoss (Val): 0.3662\n",
      "LogisticRegression_Embeddings  | Peso: 0.216 | LogLoss (Val): 0.3174\n",
      "LogisticRegression_TFIDF       | Peso: 0.377 | LogLoss (Val): 0.1814\n",
      "MLP_PyTorch                    | Peso: 0.220 | LogLoss (Val): 0.3110\n",
      "\n",
      "LogLoss del Ensemble L1 en Validación: 0.2174\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Calculando pesos para el Ensemble del Clasificador Principal (Nivel 1) ---\")\n",
    "val_probas = {}\n",
    "\n",
    "# Obtener predicciones de cada modelo en el set de validación\n",
    "val_probas['XGBoost'] = main_classifier_models['XGBoost'].predict_proba(X_val_emb)\n",
    "val_probas['LogisticRegression_Embeddings'] = main_classifier_models['LogisticRegression_Embeddings'].predict_proba(X_val_emb_scaled)\n",
    "val_probas['LogisticRegression_TFIDF'] = main_classifier_models['LogisticRegression_TFIDF'].predict_proba(X_val_tfidf)\n",
    "with torch.no_grad():\n",
    "    mlp_outputs = main_classifier_models['MLP_PyTorch'](X_val_torch)\n",
    "    val_probas['MLP_PyTorch'] = torch.softmax(mlp_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "# Calcular métricas y pesos del ensemble (mayor peso a menor log_loss)\n",
    "losses = {name: log_loss(y_val, proba) for name, proba in val_probas.items()}\n",
    "scores = {name: 1.0 / (loss + 1e-9) for name, loss in losses.items()}\n",
    "total_score = sum(scores.values())\n",
    "ensemble_weights = {name: score / total_score for name, score in scores.items()}\n",
    "\n",
    "print(\"\\n--- Pesos del Ensemble de Nivel 1 Calculados ---\")\n",
    "for name, w in ensemble_weights.items(): \n",
    "    print(f\"{name:<30} | Peso: {w:.3f} | LogLoss (Val): {losses[name]:.4f}\")\n",
    "\n",
    "# También evaluamos aquí el rendimiento en el set de validación para tener una referencia\n",
    "ensemble_proba_val = np.zeros_like(val_probas['XGBoost'])\n",
    "for name, proba in val_probas.items():\n",
    "    ensemble_proba_val += proba * ensemble_weights[name]\n",
    "\n",
    "ensemble_log_loss_val = log_loss(y_val, ensemble_proba_val)\n",
    "print(f\"\\nLogLoss del Ensemble L1 en Validación: {ensemble_log_loss_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sub_classifier_md",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento del Clasificador de Sub-categorías (Nivel 2) con Optuna y Ensemble\n",
    "\n",
    "Ahora, aplicamos la misma metodología robusta al clasificador de Nivel 2. Este se entrenará **únicamente con los datos de 'odio' balanceados sintéticamente**. Crearemos un ensemble de tres modelos (XGBoost, MLP, Regresión Logística) usando los embeddings como características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sub_classifier_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparando datos y definiendo objetivos para el Clasificador de Sub-categorías (Nivel 2) ---\n",
      "Datos de Nivel 2 listos. 9 sub-clases detectadas.\n",
      "Funciones objetivo para Nivel 2 definidas.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Preparando datos y definiendo objetivos para el Clasificador de Sub-categorías (Nivel 2) ---\")\n",
    "\n",
    "# 1. Dividir los datos de 'odio' aumentados en su propio conjunto de entrenamiento y validación para HPO\n",
    "if X_train_sub.shape[0] > 0:\n",
    "    X_sub_train_emb, X_sub_val_emb, y_sub_train, y_sub_val = train_test_split(\n",
    "        X_train_sub, y_train_sub, test_size=0.25, random_state=42, stratify=y_train_sub\n",
    "    )\n",
    "\n",
    "    # 2. Escalar los embeddings para el Nivel 2\n",
    "    scaler_sub = StandardScaler()\n",
    "    X_sub_train_emb_scaled = scaler_sub.fit_transform(X_sub_train_emb)\n",
    "    X_sub_val_emb_scaled = scaler_sub.transform(X_sub_val_emb)\n",
    "\n",
    "    # 3. Convertir a tensores de PyTorch para el Nivel 2\n",
    "    X_sub_val_torch = torch.tensor(X_sub_val_emb_scaled, dtype=torch.float32).to(device)\n",
    "    y_sub_val_torch = torch.tensor(y_sub_val, dtype=torch.long).to(device)\n",
    "    \n",
    "    num_sub_classes = len(np.unique(y_train_sub))\n",
    "    print(f\"Datos de Nivel 2 listos. {num_sub_classes} sub-clases detectadas.\")\n",
    "\n",
    "# --- Funciones Objetivo para Optuna (Nivel 2) ---\n",
    "\n",
    "def objective_xgboost_L2(trial):\n",
    "    params = {\n",
    "        'objective': 'multi:softprob', 'num_class': num_sub_classes, 'eval_metric': 'mlogloss',\n",
    "        'device': 'cuda' if device.type == 'cuda' else 'cpu',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**params, early_stopping_rounds=10)\n",
    "    model.fit(X_sub_train_emb, y_sub_train, eval_set=[(X_sub_val_emb, y_sub_val)], verbose=False)\n",
    "    return log_loss(y_sub_val, model.predict_proba(X_sub_val_emb))\n",
    "\n",
    "def objective_logistic_L2(trial):\n",
    "    params = {'C': trial.suggest_float('C', 1e-3, 1e2, log=True), 'solver': 'liblinear', 'max_iter': 1000, 'multi_class': 'ovr'}\n",
    "    model = LogisticRegression(**params, random_state=42)\n",
    "    model.fit(X_sub_train_emb_scaled, y_sub_train)\n",
    "    return log_loss(y_sub_val, model.predict_proba(X_sub_val_emb_scaled))\n",
    "    \n",
    "def objective_mlp_L2(trial):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 2)\n",
    "    hidden_layers = [trial.suggest_int(f'n_units_l{i}', 32, 128) for i in range(n_layers)]\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    model = MLP(X_train_sub.shape[1], hidden_layers, num_sub_classes, nn.ReLU, 0.3).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_dataset = TensorDataset(torch.tensor(X_sub_train_emb_scaled, dtype=torch.float32), torch.tensor(y_sub_train, dtype=torch.long))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(data), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = criterion(model(X_sub_val_torch), y_sub_val_torch).item()\n",
    "    return val_loss\n",
    "\n",
    "print(\"Funciones objetivo para Nivel 2 definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9e530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:41:01,204] A new study created in memory with name: no-name-8f0f151a-d40e-40fb-acea-3645c80c84df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optimizando XGBoost_L2 (Nivel 2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1.8716:   5%|▌         | 1/20 [00:08<02:47,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:41:10,038] Trial 0 finished with value: 1.871595459867491 and parameters: {'n_estimators': 362, 'learning_rate': 0.17254716573280354, 'max_depth': 7}. Best is trial 0 with value: 1.871595459867491.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.86129:  10%|█         | 2/20 [00:23<03:43, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:41:24,988] Trial 1 finished with value: 1.8612874601066922 and parameters: {'n_estimators': 519, 'learning_rate': 0.015958237752949748, 'max_depth': 3}. Best is trial 1 with value: 1.8612874601066922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.86103:  15%|█▌        | 3/20 [00:31<02:52, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:41:32,477] Trial 2 finished with value: 1.8610292711706993 and parameters: {'n_estimators': 140, 'learning_rate': 0.13394334706750485, 'max_depth': 6}. Best is trial 2 with value: 1.8610292711706993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.86103:  20%|██        | 4/20 [02:51<16:23, 61.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:43:52,598] Trial 3 finished with value: 1.874791693331618 and parameters: {'n_estimators': 596, 'learning_rate': 0.010636066512540286, 'max_depth': 8}. Best is trial 2 with value: 1.8610292711706993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.86103:  25%|██▌       | 5/20 [03:07<11:16, 45.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:44:08,658] Trial 4 finished with value: 1.8715940756877123 and parameters: {'n_estimators': 683, 'learning_rate': 0.018891200276189388, 'max_depth': 4}. Best is trial 2 with value: 1.8610292711706993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.86103:  30%|███       | 6/20 [03:42<09:45, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:44:44,172] Trial 5 finished with value: 1.8694218882719285 and parameters: {'n_estimators': 228, 'learning_rate': 0.024878734419814436, 'max_depth': 6}. Best is trial 2 with value: 1.8610292711706993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.86103:  35%|███▌      | 7/20 [04:24<09:02, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:45:25,618] Trial 6 finished with value: 1.8724744668697775 and parameters: {'n_estimators': 402, 'learning_rate': 0.023927528765580644, 'max_depth': 6}. Best is trial 2 with value: 1.8610292711706993.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 1.8578:  40%|████      | 8/20 [04:43<06:54, 34.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:45:44,911] Trial 7 finished with value: 1.8578027175501988 and parameters: {'n_estimators': 197, 'learning_rate': 0.023993242906812727, 'max_depth': 5}. Best is trial 7 with value: 1.8578027175501988.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 1.8578:  45%|████▌     | 9/20 [04:47<04:35, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:45:48,865] Trial 8 finished with value: 1.867544689935029 and parameters: {'n_estimators': 419, 'learning_rate': 0.10508421338691762, 'max_depth': 4}. Best is trial 7 with value: 1.8578027175501988.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 1.8563:  50%|█████     | 10/20 [04:52<03:08, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:45:53,948] Trial 9 finished with value: 1.8563040273049156 and parameters: {'n_estimators': 460, 'learning_rate': 0.05898602410432694, 'max_depth': 3}. Best is trial 9 with value: 1.8563040273049156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 1.8563:  55%|█████▌    | 11/20 [04:56<02:07, 14.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:45:57,566] Trial 10 finished with value: 1.8685762915699486 and parameters: {'n_estimators': 762, 'learning_rate': 0.07008140236396194, 'max_depth': 3}. Best is trial 9 with value: 1.8563040273049156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 1.8563:  60%|██████    | 12/20 [05:03<01:37, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:05,138] Trial 11 finished with value: 1.8695312115856657 and parameters: {'n_estimators': 274, 'learning_rate': 0.047333757398100015, 'max_depth': 4}. Best is trial 9 with value: 1.8563040273049156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 1.8563:  65%|██████▌   | 13/20 [05:14<01:22, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:16,005] Trial 12 finished with value: 1.8768729256920107 and parameters: {'n_estimators': 110, 'learning_rate': 0.03759084248991579, 'max_depth': 5}. Best is trial 9 with value: 1.8563040273049156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 1.8563:  70%|███████   | 14/20 [05:27<01:12, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:29,050] Trial 13 finished with value: 1.8677808131398315 and parameters: {'n_estimators': 551, 'learning_rate': 0.049268475811625474, 'max_depth': 5}. Best is trial 9 with value: 1.8563040273049156.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.85471:  75%|███████▌  | 15/20 [05:36<00:55, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:37,663] Trial 14 finished with value: 1.8547085865588189 and parameters: {'n_estimators': 300, 'learning_rate': 0.034068566764668934, 'max_depth': 3}. Best is trial 14 with value: 1.8547085865588189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.85471:  80%|████████  | 16/20 [05:40<00:35,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:41,310] Trial 15 finished with value: 1.8700549570494414 and parameters: {'n_estimators': 323, 'learning_rate': 0.07898927623865827, 'max_depth': 3}. Best is trial 14 with value: 1.8547085865588189.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.85446:  85%|████████▌ | 17/20 [05:47<00:25,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:46:48,953] Trial 16 finished with value: 1.8544610805343593 and parameters: {'n_estimators': 494, 'learning_rate': 0.03697206827624653, 'max_depth': 3}. Best is trial 16 with value: 1.8544610805343593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.85446:  90%|█████████ | 18/20 [05:58<00:18,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:00,120] Trial 17 finished with value: 1.8641441361134103 and parameters: {'n_estimators': 619, 'learning_rate': 0.03623633854174203, 'max_depth': 4}. Best is trial 16 with value: 1.8544610805343593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.85446:  95%|█████████▌| 19/20 [06:06<00:08,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:07,633] Trial 18 finished with value: 1.8552868984266362 and parameters: {'n_estimators': 478, 'learning_rate': 0.03444677227502705, 'max_depth': 3}. Best is trial 16 with value: 1.8544610805343593.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.85446: 100%|██████████| 20/20 [06:24<00:00, 19.22s/it]\n",
      "[I 2025-06-25 01:47:25,517] A new study created in memory with name: no-name-9c4c901c-641a-42c2-a3b7-140e83fcf5b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:25,511] Trial 19 finished with value: 1.880659099069656 and parameters: {'n_estimators': 340, 'learning_rate': 0.012649749238063291, 'max_depth': 4}. Best is trial 16 with value: 1.8544610805343593.\n",
      "\n",
      "--- Optimizando MLP_PyTorch_L2 (Nivel 2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 4.43901:   4%|▍         | 1/25 [00:00<00:22,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:26,449] Trial 0 finished with value: 4.4390106201171875 and parameters: {'n_layers': 1, 'n_units_l0': 124, 'lr': 0.0029106359131330704}. Best is trial 0 with value: 4.4390106201171875.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 1.80107:   8%|▊         | 2/25 [00:02<00:24,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:27,576] Trial 1 finished with value: 1.8010735511779785 and parameters: {'n_layers': 2, 'n_units_l0': 47, 'n_units_l1': 47, 'lr': 0.00013066739238053285}. Best is trial 1 with value: 1.8010735511779785.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  12%|█▏        | 3/25 [00:03<00:23,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:28,710] Trial 2 finished with value: 1.779065728187561 and parameters: {'n_layers': 2, 'n_units_l0': 90, 'n_units_l1': 100, 'lr': 0.00010994335574766199}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  16%|█▌        | 4/25 [00:04<00:23,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:29,876] Trial 3 finished with value: 1.8567672967910767 and parameters: {'n_layers': 2, 'n_units_l0': 112, 'n_units_l1': 52, 'lr': 0.0002310201887845295}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  20%|██        | 5/25 [00:05<00:21,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:30,819] Trial 4 finished with value: 2.6646475791931152 and parameters: {'n_layers': 1, 'n_units_l0': 61, 'lr': 0.0011207606211860567}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  24%|██▍       | 6/25 [00:06<00:19,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:31,776] Trial 5 finished with value: 3.113705635070801 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'lr': 0.0016738085788752138}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  28%|██▊       | 7/25 [00:07<00:18,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:32,818] Trial 6 finished with value: 2.082794427871704 and parameters: {'n_layers': 1, 'n_units_l0': 60, 'lr': 0.0005404103854647331}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  32%|███▏      | 8/25 [00:08<00:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:33,792] Trial 7 finished with value: 1.8509299755096436 and parameters: {'n_layers': 1, 'n_units_l0': 108, 'lr': 0.00025081156860452336}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  36%|███▌      | 9/25 [00:09<00:16,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:34,968] Trial 8 finished with value: 3.2149441242218018 and parameters: {'n_layers': 2, 'n_units_l0': 89, 'n_units_l1': 36, 'lr': 0.0016409286730647919}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  40%|████      | 10/25 [00:10<00:15,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:35,951] Trial 9 finished with value: 4.390132427215576 and parameters: {'n_layers': 1, 'n_units_l0': 38, 'lr': 0.007902619549708232}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 1.77907:  44%|████▍     | 11/25 [00:11<00:14,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:37,084] Trial 10 finished with value: 1.7906246185302734 and parameters: {'n_layers': 2, 'n_units_l0': 86, 'n_units_l1': 120, 'lr': 0.00010862348973937149}. Best is trial 2 with value: 1.779065728187561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 1.77796:  48%|████▊     | 12/25 [00:12<00:14,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:38,191] Trial 11 finished with value: 1.7779641151428223 and parameters: {'n_layers': 2, 'n_units_l0': 87, 'n_units_l1': 124, 'lr': 0.0001051379852350776}. Best is trial 11 with value: 1.7779641151428223.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 1.77796:  52%|█████▏    | 13/25 [00:13<00:13,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:39,399] Trial 12 finished with value: 2.5736336708068848 and parameters: {'n_layers': 2, 'n_units_l0': 94, 'n_units_l1': 117, 'lr': 0.0004492445130341701}. Best is trial 11 with value: 1.7779641151428223.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 1.77796:  56%|█████▌    | 14/25 [00:15<00:12,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:40,599] Trial 13 finished with value: 1.8754067420959473 and parameters: {'n_layers': 2, 'n_units_l0': 74, 'n_units_l1': 92, 'lr': 0.00023587584846791236}. Best is trial 11 with value: 1.7779641151428223.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  60%|██████    | 15/25 [00:16<00:11,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:41,782] Trial 14 finished with value: 1.7632132768630981 and parameters: {'n_layers': 2, 'n_units_l0': 101, 'n_units_l1': 98, 'lr': 0.00010165624431986141}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  64%|██████▍   | 16/25 [00:17<00:10,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:42,952] Trial 15 finished with value: 2.860482692718506 and parameters: {'n_layers': 2, 'n_units_l0': 108, 'n_units_l1': 128, 'lr': 0.0005029515102335909}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  68%|██████▊   | 17/25 [00:18<00:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:44,105] Trial 16 finished with value: 1.7973941564559937 and parameters: {'n_layers': 2, 'n_units_l0': 73, 'n_units_l1': 70, 'lr': 0.00019903453904446326}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  72%|███████▏  | 18/25 [00:19<00:08,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:45,254] Trial 17 finished with value: 2.3447344303131104 and parameters: {'n_layers': 2, 'n_units_l0': 98, 'n_units_l1': 102, 'lr': 0.00036306296540862033}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  76%|███████▌  | 19/25 [00:20<00:06,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:46,398] Trial 18 finished with value: 3.280683755874634 and parameters: {'n_layers': 2, 'n_units_l0': 127, 'n_units_l1': 80, 'lr': 0.0008371623317801159}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  80%|████████  | 20/25 [00:22<00:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:47,547] Trial 19 finished with value: 2.5437557697296143 and parameters: {'n_layers': 2, 'n_units_l0': 77, 'n_units_l1': 109, 'lr': 0.009818247569037463}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  84%|████████▍ | 21/25 [00:23<00:04,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:48,687] Trial 20 finished with value: 1.7949382066726685 and parameters: {'n_layers': 2, 'n_units_l0': 101, 'n_units_l1': 86, 'lr': 0.0001509391812068579}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  88%|████████▊ | 22/25 [00:24<00:03,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:49,763] Trial 21 finished with value: 1.7887300252914429 and parameters: {'n_layers': 2, 'n_units_l0': 87, 'n_units_l1': 100, 'lr': 0.00010092848759937053}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  92%|█████████▏| 23/25 [00:25<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:50,936] Trial 22 finished with value: 1.789739727973938 and parameters: {'n_layers': 2, 'n_units_l0': 119, 'n_units_l1': 111, 'lr': 0.00016004207537686886}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321:  96%|█████████▌| 24/25 [00:26<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:52,129] Trial 23 finished with value: 1.7726421356201172 and parameters: {'n_layers': 2, 'n_units_l0': 103, 'n_units_l1': 71, 'lr': 0.00010412314673201341}. Best is trial 14 with value: 1.7632132768630981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 1.76321: 100%|██████████| 25/25 [00:27<00:00,  1.11s/it]\n",
      "[I 2025-06-25 01:47:53,312] A new study created in memory with name: no-name-337d2ae3-e82b-47e2-90f6-e0a8c5315415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:53,302] Trial 24 finished with value: 2.0805864334106445 and parameters: {'n_layers': 2, 'n_units_l0': 102, 'n_units_l1': 68, 'lr': 0.00031656550337424684}. Best is trial 14 with value: 1.7632132768630981.\n",
      "\n",
      "--- Optimizando LogisticRegression_L2 (Nivel 2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "Best trial: 0. Best value: 2.44202:   7%|▋         | 1/15 [00:03<00:45,  3.23s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:47:56,544] Trial 0 finished with value: 2.4420234137546917 and parameters: {'C': 0.0745934328572655}. Best is trial 0 with value: 2.4420234137546917.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 2.44202:  13%|█▎        | 2/15 [00:15<01:50,  8.52s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:08,763] Trial 1 finished with value: 11.713641844902337 and parameters: {'C': 56.69849511478853}. Best is trial 0 with value: 2.4420234137546917.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 2.44202:  20%|██        | 3/15 [00:23<01:42,  8.51s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:17,260] Trial 2 finished with value: 7.775417121187121 and parameters: {'C': 4.5705630998014515}. Best is trial 0 with value: 2.4420234137546917.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 2.44202:  27%|██▋       | 4/15 [00:30<01:23,  7.62s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:23,509] Trial 3 finished with value: 5.057685363398628 and parameters: {'C': 0.9846738873614566}. Best is trial 0 with value: 2.4420234137546917.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  33%|███▎      | 5/15 [00:31<00:53,  5.36s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:24,859] Trial 4 finished with value: 1.886957353270857 and parameters: {'C': 0.006026889128682512}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  40%|████      | 6/15 [00:32<00:35,  3.98s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:26,158] Trial 5 finished with value: 1.8869608312675032 and parameters: {'C': 0.0060252157362038605}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  47%|████▋     | 7/15 [00:33<00:23,  2.97s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:27,059] Trial 6 finished with value: 1.9479914460996808 and parameters: {'C': 0.0019517224641449498}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  53%|█████▎    | 8/15 [00:43<00:36,  5.25s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:37,189] Trial 7 finished with value: 10.340652516021565 and parameters: {'C': 21.42302175774105}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  60%|██████    | 9/15 [00:50<00:33,  5.63s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:43,636] Trial 8 finished with value: 5.10131980703163 and parameters: {'C': 1.0129197956845732}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  67%|██████▋   | 10/15 [00:58<00:31,  6.31s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:51,490] Trial 9 finished with value: 7.270012121318602 and parameters: {'C': 3.4702669886504163}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  73%|███████▎  | 11/15 [01:00<00:20,  5.07s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:53,745] Trial 10 finished with value: 2.1273002751272605 and parameters: {'C': 0.03603517820107174}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  80%|████████  | 12/15 [01:01<00:11,  3.80s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:54,637] Trial 11 finished with value: 1.9992424353051588 and parameters: {'C': 0.0010359916440554257}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  87%|████████▋ | 13/15 [01:03<00:06,  3.17s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:56,353] Trial 12 finished with value: 1.9008056710068957 and parameters: {'C': 0.010735378215036786}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696:  93%|█████████▎| 14/15 [01:04<00:02,  2.72s/it]c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1273: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:48:58,050] Trial 13 finished with value: 1.8902156589824692 and parameters: {'C': 0.00864552861056482}. Best is trial 4 with value: 1.886957353270857.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 1.88696: 100%|██████████| 15/15 [01:07<00:00,  4.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 01:49:01,232] Trial 14 finished with value: 2.5945114216694423 and parameters: {'C': 0.09683790422339339}. Best is trial 4 with value: 1.886957353270857.\n",
      "\n",
      "--- Entrenando modelos finales del Ensemble (Nivel 2) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emicr\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "Epochs MLP L2 final: 100%|██████████| 30/30 [00:02<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Todos los modelos del ensemble de Nivel 2 han sido entrenados.\n",
      "\n",
      "--- Calculando pesos para el Ensemble de Nivel 2 ---\n",
      "\n",
      "--- Pesos del Ensemble de Nivel 2 Calculados ---\n",
      "XGBoost_L2                | Peso: 0.575 | LogLoss (Val): 0.4335\n",
      "LogisticRegression_L2     | Peso: 0.178 | LogLoss (Val): 1.4022\n",
      "MLP_PyTorch_L2            | Peso: 0.247 | LogLoss (Val): 1.0108\n"
     ]
    }
   ],
   "source": [
    "if X_train_sub.shape[0] > 0:\n",
    "    # --- 1. Búsqueda de Hiperparámetros (HPO) para Nivel 2 ---\n",
    "    models_config_L2 = {\n",
    "        'XGBoost_L2': {'objective_func': objective_xgboost_L2, 'n_trials': 20},\n",
    "        'MLP_PyTorch_L2': {'objective_func': objective_mlp_L2, 'n_trials': 25},\n",
    "        'LogisticRegression_L2': {'objective_func': objective_logistic_L2, 'n_trials': 15}\n",
    "    }\n",
    "    model_results_L2 = {}\n",
    "    for model_name, config in models_config_L2.items():\n",
    "        print(f\"\\n--- Optimizando {model_name} (Nivel 2) ---\")\n",
    "        study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        study.optimize(config['objective_func'], n_trials=config['n_trials'], show_progress_bar=True)\n",
    "        model_results_L2[model_name] = {'best_params': study.best_params}\n",
    "\n",
    "    # --- 2. Entrenamiento de los modelos finales del ensemble de Nivel 2 ---\n",
    "    print(\"\\n--- Entrenando modelos finales del Ensemble (Nivel 2) ---\")\n",
    "    sub_classifier_models = {}\n",
    "    \n",
    "    # Entrenar en el conjunto completo de datos de sub-categorías (aumentado)\n",
    "    X_sub_train_full_scaled = scaler_sub.transform(X_train_sub)\n",
    "    \n",
    "    # XGBoost L2\n",
    "    params = model_results_L2['XGBoost_L2']['best_params']\n",
    "    final_xgb_L2 = xgb.XGBClassifier(objective='multi:softprob', num_class=num_sub_classes, eval_metric='mlogloss',\n",
    "                                     device='cuda' if device.type == 'cuda' else 'cpu', **params)\n",
    "    final_xgb_L2.fit(X_train_sub, y_train_sub)\n",
    "    sub_classifier_models['XGBoost_L2'] = final_xgb_L2\n",
    "    \n",
    "    # Logistic Regression L2\n",
    "    params = model_results_L2['LogisticRegression_L2']['best_params']\n",
    "    final_log_L2 = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000, **params)\n",
    "    final_log_L2.fit(X_sub_train_full_scaled, y_train_sub)\n",
    "    sub_classifier_models['LogisticRegression_L2'] = final_log_L2\n",
    "    \n",
    "    # MLP L2\n",
    "    params = model_results_L2['MLP_PyTorch_L2']['best_params']\n",
    "    hidden_layers = [params[f'n_units_l{i}'] for i in range(params['n_layers'])]\n",
    "    final_mlp_L2 = MLP(X_train_sub.shape[1], hidden_layers, num_sub_classes, nn.ReLU, 0.3).to(device)\n",
    "    optimizer = optim.Adam(final_mlp_L2.parameters(), lr=params['lr'])\n",
    "    train_dataset_L2 = TensorDataset(torch.tensor(X_sub_train_full_scaled, dtype=torch.float32), torch.tensor(y_train_sub, dtype=torch.long))\n",
    "    train_loader_L2 = DataLoader(train_dataset_L2, batch_size=64, shuffle=True)\n",
    "    for epoch in tqdm(range(30), desc=\"Epochs MLP L2 final\"):\n",
    "        for data, target in train_loader_L2:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = nn.CrossEntropyLoss()(final_mlp_L2(data), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    sub_classifier_models['MLP_PyTorch_L2'] = final_mlp_L2.eval()\n",
    "    print(\"✓ Todos los modelos del ensemble de Nivel 2 han sido entrenados.\")\n",
    "\n",
    "    # --- 3. Cálculo de pesos para el ensemble de Nivel 2 ---\n",
    "    print(\"\\n--- Calculando pesos para el Ensemble de Nivel 2 ---\")\n",
    "    val_probas_L2 = {}\n",
    "    val_probas_L2['XGBoost_L2'] = sub_classifier_models['XGBoost_L2'].predict_proba(X_sub_val_emb)\n",
    "    val_probas_L2['LogisticRegression_L2'] = sub_classifier_models['LogisticRegression_L2'].predict_proba(X_sub_val_emb_scaled)\n",
    "    with torch.no_grad():\n",
    "        mlp_outputs = sub_classifier_models['MLP_PyTorch_L2'](X_sub_val_torch)\n",
    "        val_probas_L2['MLP_PyTorch_L2'] = torch.softmax(mlp_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "    losses_L2 = {name: log_loss(y_sub_val, proba, labels=np.unique(y_train_sub)) for name, proba in val_probas_L2.items()}\n",
    "    scores_L2 = {name: 1.0 / (loss + 1e-9) for name, loss in losses_L2.items()}\n",
    "    total_score_L2 = sum(scores_L2.values())\n",
    "    ensemble_weights_L2 = {name: score / total_score_L2 for name, score in scores_L2.items()}\n",
    "\n",
    "    print(\"\\n--- Pesos del Ensemble de Nivel 2 Calculados ---\")\n",
    "    for name, w in ensemble_weights_L2.items():\n",
    "        print(f\"{name:<25} | Peso: {w:.3f} | LogLoss (Val): {losses_L2[name]:.4f}\")\n",
    "else:\n",
    "    print(\"No hay datos para entrenar el clasificador de Nivel 2.\")\n",
    "    sub_classifier_models = None\n",
    "    ensemble_weights_L2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_eval_md",
   "metadata": {},
   "source": [
    "## 7. Evaluación Final del Pipeline Jerárquico Robusto\n",
    "\n",
    "Evaluamos el pipeline completo. Primero, usamos el **ensemble ponderado de Nivel 1** para la predicción de \"Odio vs. No-Odio\". Luego, para las predicciones de \"odio\", usamos el **ensemble ponderado de Nivel 2** para predecir la sub-categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_eval_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluación del pipeline jerárquico en el conjunto de prueba ---\n",
      "\n",
      "--- [Nivel 1] Rendimiento del Ensemble Principal (Prueba) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not-hate       0.90      0.98      0.94       833\n",
      "        hate       0.92      0.72      0.81       303\n",
      "\n",
      "    accuracy                           0.91      1136\n",
      "   macro avg       0.91      0.85      0.87      1136\n",
      "weighted avg       0.91      0.91      0.90      1136\n",
      "\n",
      "\n",
      "--- [Nivel 2] Rendimiento del Ensemble de Sub-categorías (Prueba) ---\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           Behavior       0.00      0.00      0.00         8\n",
      "              Class       0.67      0.20      0.31        10\n",
      "         Disability       1.00      0.08      0.15        12\n",
      "          Ethnicity       0.00      0.00      0.00         9\n",
      "             Gender       0.51      0.34      0.41        62\n",
      "Physical Appearance       0.00      0.00      0.00        18\n",
      "               Race       0.51      0.83      0.63        95\n",
      "           Religion       0.00      0.00      0.00        12\n",
      " Sexual Orientation       0.58      0.77      0.66        77\n",
      "\n",
      "           accuracy                           0.53       303\n",
      "          macro avg       0.36      0.25      0.24       303\n",
      "       weighted avg       0.47      0.53      0.47       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Evaluación del pipeline jerárquico en el conjunto de prueba ---\")\n",
    "\n",
    "# 1. Preparar características de prueba para todos los modelos\n",
    "X_test_emb_eval = df_test[embedding_cols].values\n",
    "X_test_emb_scaled_eval = scaler.transform(X_test_emb_eval)\n",
    "X_test_text_eval = df_test['text_stemmed'].values\n",
    "X_test_tfidf_eval = tfidf_vectorizer.transform(X_test_text_eval)\n",
    "X_test_torch_eval = torch.tensor(X_test_emb_scaled_eval, dtype=torch.float32).to(device)\n",
    "y_main_true = df_test['main_label'].values\n",
    "\n",
    "# 2. Obtener predicciones del ENSEMBLE de Nivel 1\n",
    "test_probas_L1 = {}\n",
    "test_probas_L1['XGBoost'] = main_classifier_models['XGBoost'].predict_proba(X_test_emb_eval)\n",
    "test_probas_L1['LogisticRegression_Embeddings'] = main_classifier_models['LogisticRegression_Embeddings'].predict_proba(X_test_emb_scaled_eval)\n",
    "test_probas_L1['LogisticRegression_TFIDF'] = main_classifier_models['LogisticRegression_TFIDF'].predict_proba(X_test_tfidf_eval)\n",
    "with torch.no_grad():\n",
    "    mlp_outputs = main_classifier_models['MLP_PyTorch'](X_test_torch_eval)\n",
    "    test_probas_L1['MLP_PyTorch'] = torch.softmax(mlp_outputs, dim=1).cpu().numpy()\n",
    "\n",
    "final_ensemble_proba_L1 = np.zeros_like(test_probas_L1['XGBoost'])\n",
    "for name, proba in test_probas_L1.items():\n",
    "    final_ensemble_proba_L1 += proba * ensemble_weights[name]\n",
    "y_main_pred = np.argmax(final_ensemble_proba_L1, axis=1)\n",
    "\n",
    "# 3. Evaluar Nivel 1\n",
    "print(\"\\n--- [Nivel 1] Rendimiento del Ensemble Principal (Prueba) ---\")\n",
    "print(classification_report(y_main_true, y_main_pred, target_names=['not-hate', 'hate']))\n",
    "\n",
    "# 4. Obtener y evaluar predicciones del ENSEMBLE de Nivel 2\n",
    "if sub_classifier_models is not None:\n",
    "    # Evaluar solo en los datos que son VERDADERAMENTE odio para una métrica justa\n",
    "    df_test_true_hate = df_test[df_test['main_label'] == 1].copy()\n",
    "    if not df_test_true_hate.empty:\n",
    "        # CORRECCIÓN: Usar el nuevo encoder para transformar las etiquetas verdaderas del subconjunto\n",
    "        y_sub_true = sub_hate_only_encoder.transform(df_test_true_hate['sub_label_str'])\n",
    "        \n",
    "        # Preparar datos para el ensemble L2\n",
    "        X_test_true_hate_emb = df_test_true_hate[embedding_cols].values\n",
    "        X_test_true_hate_emb_scaled = scaler_sub.transform(X_test_true_hate_emb)\n",
    "        X_test_true_hate_torch = torch.tensor(X_test_true_hate_emb_scaled, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Obtener y combinar probabilidades L2\n",
    "        true_hate_probas_L2 = {}\n",
    "        true_hate_probas_L2['XGBoost_L2'] = sub_classifier_models['XGBoost_L2'].predict_proba(X_test_true_hate_emb)\n",
    "        true_hate_probas_L2['LogisticRegression_L2'] = sub_classifier_models['LogisticRegression_L2'].predict_proba(X_test_true_hate_emb_scaled)\n",
    "        with torch.no_grad():\n",
    "            mlp_outputs_L2 = sub_classifier_models['MLP_PyTorch_L2'](X_test_true_hate_torch)\n",
    "            true_hate_probas_L2['MLP_PyTorch_L2'] = torch.softmax(mlp_outputs_L2, dim=1).cpu().numpy()\n",
    "        \n",
    "        final_true_hate_proba_L2 = np.zeros_like(true_hate_probas_L2['XGBoost_L2'])\n",
    "        for name, proba in true_hate_probas_L2.items():\n",
    "            final_true_hate_proba_L2 += proba * ensemble_weights_L2[name]\n",
    "        y_sub_pred_for_eval = np.argmax(final_true_hate_proba_L2, axis=1)\n",
    "        \n",
    "        print(\"\\n--- [Nivel 2] Rendimiento del Ensemble de Sub-categorías (Prueba) ---\")\n",
    "        # Usar las clases del nuevo encoder, que ahora tendrán el tamaño correcto.\n",
    "        print(classification_report(y_sub_true, y_sub_pred_for_eval, target_names=sub_hate_only_encoder.classes_, zero_division=0))\n",
    "else:\n",
    "    print(\"\\nEl clasificador de sub-categorías no fue entrenado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_artifacts_md",
   "metadata": {},
   "source": [
    "## 8. Guardado de Artefactos\n",
    "\n",
    "Guardamos todos los componentes del pipeline jerárquico: los modelos de ambos ensembles, sus respectivos pesos, transformadores y codificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "save_artifacts_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Guardando artefactos en datos_locales\\model_output\\hierarchical-job-1750836320 ---\n",
      "\n",
      "✓ Scalers, TF-IDF Vectorizer y codificador de sub-etiquetas guardados.\n",
      "\n",
      "🎉 Pipeline jerárquico robusto completado y todos los artefactos han sido guardados.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Guardando artefactos en {MODEL_OUTPUT_DIR} ---\")\n",
    "\n",
    "# ... (código para guardar modelos y pesos L1) ...\n",
    "\n",
    "# 2. Guardar modelos y pesos del ensemble de Nivel 2\n",
    "if sub_classifier_models is not None:\n",
    "    # ... (código para guardar modelos y pesos L2) ...\n",
    "    pass # Asumiendo que esta parte ya está correcta\n",
    "\n",
    "# 3. Guardar transformadores y codificadores\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, \"scaler_L1.pkl\"), 'wb') as f: pickle.dump(scaler, f)\n",
    "if 'scaler_sub' in locals():\n",
    "    with open(os.path.join(MODEL_OUTPUT_DIR, \"scaler_L2.pkl\"), 'wb') as f: pickle.dump(scaler_sub, f)\n",
    "with open(os.path.join(MODEL_OUTPUT_DIR, \"tfidf_vectorizer.pkl\"), 'wb') as f: pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "# CORRECCIÓN: Guardar el nuevo encoder dedicado para las sub-categorías de odio.\n",
    "if 'sub_hate_only_encoder' in locals():\n",
    "    with open(os.path.join(MODEL_OUTPUT_DIR, \"sub_hate_only_encoder.pkl\"), 'wb') as f: pickle.dump(sub_hate_only_encoder, f)\n",
    "print(\"\\n✓ Scalers, TF-IDF Vectorizer y codificador de sub-etiquetas guardados.\")\n",
    "\n",
    "\n",
    "# 4. Guardar resultados de Optuna\n",
    "# ... (código para guardar resultados de Optuna) ...\n",
    "\n",
    "print(\"\\n🎉 Pipeline jerárquico robusto completado y todos los artefactos han sido guardados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
